{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rfarwell/MPhys/blob/main/CNN4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# To do list\n",
        "1. Figure out normalization when creating the datasets\n",
        "2. Get to work with tensorboard to see if weights are changing\n",
        "3. Issue: currently the network reaches approx minimum loss after just 7 batches of 1 epoch. This may be because the network is very simple or other factors."
      ],
      "metadata": {
        "id": "e9Hd9ZIlACIM"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MfWFoJBL2P6A",
        "outputId": "0e40cffb-0447-42a8-f094-bfc3f0bba84d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (1.10.0+cu111)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.7/dist-packages (0.11.1+cu111)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch) (3.10.0.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchvision) (1.19.5)\n",
            "Requirement already satisfied: pillow!=8.3.0,>=5.3.0 in /usr/local/lib/python3.7/dist-packages (from torchvision) (7.1.2)\n",
            "Requirement already satisfied: opencv-contrib-python in /usr/local/lib/python3.7/dist-packages (4.1.2.30)\n",
            "Requirement already satisfied: numpy>=1.14.5 in /usr/local/lib/python3.7/dist-packages (from opencv-contrib-python) (1.19.5)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (1.0.1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn) (1.1.0)\n",
            "Requirement already satisfied: numpy>=1.14.6 in /usr/local/lib/python3.7/dist-packages (from scikit-learn) (1.19.5)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn) (1.4.1)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn) (3.0.0)\n",
            "Collecting SimpleITK\n",
            "  Downloading SimpleITK-2.1.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (48.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 48.4 MB 48.3 MB/s \n",
            "\u001b[?25hInstalling collected packages: SimpleITK\n",
            "Successfully installed SimpleITK-2.1.1\n"
          ]
        }
      ],
      "source": [
        "!pip install torch torchvision\n",
        "!pip install opencv-contrib-python\n",
        "!pip install scikit-learn\n",
        "!pip install SimpleITK\n",
        "\n",
        "import numpy as np\n",
        "import random\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import SimpleITK as sitk\n",
        "import torch\n",
        "\n",
        "from mpl_toolkits.mplot3d import Axes3D\n",
        "from torch.nn import Module\n",
        "from torch.nn import Conv3d\n",
        "from torch.nn import Linear\n",
        "from torch.nn import MaxPool2d\n",
        "from torch.nn import ReLU\n",
        "from torch.nn import LogSoftmax\n",
        "from torch import flatten\n",
        "from torch import nn\n",
        "from torch import reshape\n",
        "from torch.utils.data import Dataset\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import transforms\n",
        "from torchvision import datasets\n",
        "from torch.optim import Adam\n",
        "import torchvision.models as models\n",
        "from torch.autograd import Variable"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "95pHZBRQ2Zbl",
        "outputId": "6d9e9685-46e5-4ac2-c054-7dc1b2ca4e3e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j-zAX1vZ2bSU",
        "outputId": "5904ac79-5121-4bc9-8527-e5b6da4de837"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using cuda device\n",
            "/content/gdrive/MyDrive/MPhys/Data/COLAB-Clinical-Data.csv\n"
          ]
        }
      ],
      "source": [
        "# Connect to GPU is available\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "print(f'Using {device} device')\n",
        "# /content/gdrive/MyDrive/MPhys/Data/COLAB-Clinical-Data.csv\n",
        "# Specify project folder location\n",
        "project_folder = \"/content/gdrive/MyDrive/MPhys/Data\"\n",
        "clinical_data_filename = \"COLAB-Clinical-Data.csv\"\n",
        "print(os.path.join(project_folder, clinical_data_filename))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7HU0Og4e2k_k",
        "outputId": "08fb9d03-da84-4b6b-e776-8e78b725a9c7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Length of metadata array is 100\n",
            "Dead counter after 547.5 days: 60\n",
            "Alive counter after 547.5 days: 40\n",
            "No-info counter after 547.5 days: 0\n",
            "The alive and dead arrays have been sorted (randomly) so that they are both of length 40\n",
            "56\n"
          ]
        }
      ],
      "source": [
        "def equalise_array_lengths(array_1, array_2) :\n",
        "  \"\"\"\n",
        "  This functions takes in the arguments of two lists and makes sure they are returned as the same length.\n",
        "\n",
        "  Rory Farwell 02/12/2021\n",
        "  \"\"\"\n",
        "  # output_array = []\n",
        "  if len(array_1) > len(array_2) :\n",
        "    array_1 = array_1[:len(array_2)]\n",
        "  elif len(array_1) < len(array_2) :\n",
        "    array_2 = array_2[:len(array_1)]\n",
        "  #print(np.vstack((array_1, array_2)))\n",
        "  # output_array.append(array_1)\n",
        "  # output_array.append(array_2)\n",
        "  return (array_1, array_2)\n",
        "\n",
        "def remove_same_elements(small_array, long_array) :\n",
        "  \"\"\"\n",
        "  For use in the context, all the elements in small_array come from long_array.\n",
        "  This function will remove all of the elements used in small_array from_long_array.  \n",
        "  \"\"\"\n",
        "  for element in small_array :\n",
        "    long_array.remove(element)\n",
        "  return long_array\n",
        "\n",
        "def create_subgroup(input_array, original_array_length, desired_percentage) :\n",
        "  \"\"\"\n",
        "  This function outputs a subgroup array (e.g. training array) using a specified output array name,\n",
        "  input array and percentage length\n",
        "  \"\"\"\n",
        "  desired_length = int(original_array_length * desired_percentage)\n",
        "  output_array = random.sample(input_array, desired_length)\n",
        "  return output_array\n",
        "  \n",
        "\n",
        "# Open the metadata.csv file, convert to an array, and remove column headers\n",
        "metadata_file = os.path.join(project_folder, clinical_data_filename)\n",
        "metadata = np.genfromtxt(metadata_file, comments = '%', dtype=\"str\", delimiter=\",\")\n",
        "print(f\"Length of metadata array is {len(metadata)}\")\n",
        "\n",
        "outcome_type = 1 #int(input(\"Select which outcome you are aiming to predict \\n(1=Locoregional, 2=Distant Metastasis, 3=Death):\"))\n",
        "check_day = 3000 #int(input(\"Select the number of days at which to check for event:\"))\n",
        "which_patients = 1 #int(input(\"Do you want to include patients whose last follow up is before the check day? (no = 0, yes = 1):\"))\n",
        "patient_with_event = []\n",
        "patient_no_event = []\n",
        "outcomes_train = []\n",
        "outcomes_test = []\n",
        "images = []\n",
        "\n",
        "check_day = 365 * 1.5 # This is defining the timeframe for which our CNN will consider the binary output (in days)\n",
        "\n",
        "patient_IDs = metadata[:,0]\n",
        "time_markers = metadata[:,8]\n",
        "dead_statuses = metadata[:,9]\n",
        "\n",
        "time_markers = time_markers.astype(np.float32)\n",
        "dead_statuses = dead_statuses.astype(np.float32)\n",
        "\n",
        "\n",
        "check_day_dead_statuses = []\n",
        "\n",
        "counter = 0 \n",
        "\n",
        "dead_counter = 0\n",
        "alive_counter = 0\n",
        "no_info_counter = 0\n",
        "\n",
        "dead_patient_array = []\n",
        "alive_patient_array = []\n",
        "\n",
        "for i in range(len(dead_statuses)) :\n",
        "  # counter+=1\n",
        "  # print(counter)\n",
        "  temp_dead_status = dead_statuses[i]\n",
        "  #print(temp_dead_status)\n",
        "  temp_time_marker = time_markers[i]\n",
        "  #print(temp_time_marker)\n",
        "  if temp_dead_status == 1 : #if the patient is dead\n",
        "    #print('y')\n",
        "    if temp_time_marker < check_day :\n",
        "      check_day_dead_statuses.append(1) #confirms that the patient was dead after time 'check_day'\n",
        "      dead_patient_array.append([patient_IDs[i], 1])\n",
        "      dead_counter += 1\n",
        "      continue\n",
        "    elif temp_time_marker > check_day :\n",
        "      check_day_dead_statuses.append(0)\n",
        "      alive_patient_array.append([patient_IDs[i], 0])\n",
        "      alive_counter += 1\n",
        "      continue\n",
        "  elif temp_dead_status == 0 : #if the patient is alive\n",
        "    #print('n')\n",
        "    if temp_time_marker < check_day :\n",
        "      no_info_counter += 1\n",
        "      continue\n",
        "    elif temp_time_marker > check_day :\n",
        "      check_day_dead_statuses.append(0)\n",
        "      alive_patient_array.append([patient_IDs[i], 0])\n",
        "      alive_counter += 1\n",
        "      continue\n",
        "print(f\"Dead counter after {check_day} days: {dead_counter}\")\n",
        "print(f\"Alive counter after {check_day} days: {alive_counter}\")\n",
        "print(f\"No-info counter after {check_day} days: {no_info_counter}\")\n",
        "\n",
        "# print(len(dead_patient_array), dead_patient_array)\n",
        "# print(len(alive_patient_array), alive_patient_array)\n",
        "\n",
        "training_array = []\n",
        "testing_array = []\n",
        "validation_array = []\n",
        "\n",
        "random.shuffle(dead_patient_array) #shuffling both arrays to ensure random selection of patient data\n",
        "random.shuffle(alive_patient_array)\n",
        "\n",
        "# equalising the length of the 'dead' and 'alive' arrays so that we can ensure optimum training proportions\n",
        "new_dead_patient_array = equalise_array_lengths(dead_patient_array, alive_patient_array)[0]\n",
        "new_alive_patient_array = equalise_array_lengths(dead_patient_array, alive_patient_array)[1]\n",
        "print(f\"The alive and dead arrays have been sorted (randomly) so that they are both of length {len(new_dead_patient_array)}\")\n",
        "\n",
        "# print(new_dead_patient_array)\n",
        "# print(new_alive_patient_array)\n",
        "# print(len(new_dead_patient_array))\n",
        "# print(len(new_alive_patient_array))\n",
        "\n",
        "equalised_array_length = len(new_alive_patient_array)\n",
        "\n",
        "train_patients_dead = create_subgroup(new_dead_patient_array, equalised_array_length, 0.7)\n",
        "train_patients_alive = create_subgroup(new_alive_patient_array, equalised_array_length, 0.7)\n",
        "# print(len(train_patients_dead))\n",
        "# print(len(train_patients_alive))\n",
        "\n",
        "new_dead_patient_array = remove_same_elements(train_patients_dead, new_dead_patient_array)\n",
        "new_alive_patient_array = remove_same_elements(train_patients_alive, new_alive_patient_array)\n",
        "# print(len(new_dead_patient_array))\n",
        "# print(len(new_alive_patient_array))\n",
        "\n",
        "test_patients_dead = create_subgroup(new_dead_patient_array, equalised_array_length, 0.15)\n",
        "test_patients_alive = create_subgroup(new_alive_patient_array, equalised_array_length, 0.15)\n",
        "# print(len(test_patients_dead))\n",
        "# print(len(test_patients_alive))\n",
        "\n",
        "new_dead_patient_array = remove_same_elements(test_patients_dead, new_dead_patient_array)\n",
        "new_alive_patient_array = remove_same_elements(test_patients_alive, new_alive_patient_array)\n",
        "# print(len(new_dead_patient_array))\n",
        "# print(len(new_alive_patient_array))\n",
        "\n",
        "validate_patients_dead = create_subgroup(new_dead_patient_array, equalised_array_length, 0.15)\n",
        "validate_patients_alive = create_subgroup(new_alive_patient_array, equalised_array_length, 0.15)\n",
        "# print(len(validate_patients_dead))\n",
        "# print(len(validate_patients_alive))\n",
        "\n",
        "new_dead_patient_array = remove_same_elements(validate_patients_dead, new_dead_patient_array)\n",
        "new_alive_patient_array = remove_same_elements(validate_patients_alive, new_alive_patient_array)\n",
        "# print(len(new_dead_patient_array))\n",
        "# print(len(new_alive_patient_array))\n",
        "\n",
        "\n",
        "outcomes_train = train_patients_dead + train_patients_alive\n",
        "outcomes_test = test_patients_dead + test_patients_alive\n",
        "outcomes_validate = validate_patients_dead + validate_patients_alive\n",
        "\n",
        "print(len(outcomes_train))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "qt8pEoBq20QD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8de42a5e-6b91-4a2c-a3ce-9fde06bb988f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(-1024., dtype=torch.float64)\n",
            "tensor(-1021.4073, dtype=torch.float64) tensor(52.0958, dtype=torch.float64)\n",
            "1\n",
            "tensor(-1024.)\n",
            "tensor(-1022.9258) tensor(32.4395)\n",
            "1\n",
            "tensor(-0.0498, dtype=torch.float64)\n",
            "tensor(-1.3302e-16, dtype=torch.float64) tensor(1.0000, dtype=torch.float64)\n",
            "1\n",
            "tensor(-0.0331)\n",
            "tensor(5.7648e-07) tensor(1.)\n",
            "1\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "from torchvision.io import read_image\n",
        "\n",
        "# Normalize class added at 10pm 12/12/2021\n",
        "class Normalize():\n",
        "  def __init__(self):\n",
        "    pass\n",
        "  \n",
        "  # def __call__(self, sample):\n",
        "  #   inputs, targets = sample\n",
        "  #   inputs = transforms.Normalize(mean = 0.5, std = 0.5)\n",
        "  #   return inputs, targets\n",
        "  def __call__(self,vol):\n",
        "    vol =(vol-vol.mean())/vol.std()\n",
        "    return vol\n",
        "\n",
        "transform = transforms.Compose(\n",
        "    [transforms.ToTensor(), transforms.Normalize(mean = 0.5, std = 0.5)] #added at 10:31pm 13/12/2021 to normalize the inputs\n",
        ")\n",
        "\n",
        "transform = transforms.Compose(\n",
        "    [transforms.ToTensor(), Normalize() ] #added at 11:00pm 13/12/2021 to normalize the inputs. THIS NORMALIZES to mean = 0 and std = -1\n",
        ")\n",
        "\n",
        "\n",
        "class ImageDataset(Dataset) :\n",
        "  def __init__(self, annotations, img_dir, transform = transform, target_transform = None) :\n",
        "    self.img_labels = annotations\n",
        "    self.img_dir = img_dir\n",
        "    self.transform = transform\n",
        "    self.target_transform = target_transform\n",
        "\n",
        "  def __len__(self) :\n",
        "    return len(self.img_labels)\n",
        "\n",
        "  def __getitem__(self,idx) :\n",
        "    img_path = os.path.join(self.img_dir, self.img_labels[idx][0] + \"-GTV-1.nii\" )\n",
        "    image_sitk = sitk.ReadImage(img_path)\n",
        "    image = sitk.GetArrayFromImage(image_sitk)\n",
        "    label = self.img_labels[idx][1]\n",
        "    if self.transform :\n",
        "      image = self.transform(image)\n",
        "    if self.target_transform :\n",
        "      label = self.target_transform(label)\n",
        "    return image,label\n",
        "\n",
        "training_data = ImageDataset(outcomes_train, os.path.join(project_folder, \"Textured_Masks\"), transform = transforms.ToTensor())\n",
        "validation_data = ImageDataset(outcomes_validate, os.path.join(project_folder, \"Textured_Masks\"), transform = transforms.ToTensor())\n",
        "test_data = ImageDataset(outcomes_test, os.path.join(project_folder, \"Textured_Masks\"), transform = transforms.ToTensor())\n",
        "print(training_data[0][0][0][0][0])\n",
        "print(training_data[0][0].mean(), training_data[0][0].std())\n",
        "print(training_data[0][1])\n",
        "print(training_data[1][0][0][0][0])\n",
        "print(training_data[1][0].mean(), training_data[1][0].std())\n",
        "print(training_data[1][1])\n",
        "\n",
        "training_data = ImageDataset(outcomes_train, os.path.join(project_folder, \"Textured_Masks\"), transform = transform)\n",
        "validation_data = ImageDataset(outcomes_validate, os.path.join(project_folder, \"Textured_Masks\"), transform = transform)\n",
        "test_data = ImageDataset(outcomes_test, os.path.join(project_folder, \"Textured_Masks\"), transform = transform) \n",
        "print(training_data[0][0][0][0][0])\n",
        "print(training_data[0][0].mean(), training_data[0][0].std())\n",
        "print(training_data[0][1])\n",
        "print(training_data[1][0][0][0][0])\n",
        "print(training_data[1][0].mean(), training_data[1][0].std())\n",
        "print(training_data[1][1])\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "0KfrxkyK2-sj"
      },
      "outputs": [],
      "source": [
        "train_dataloader = DataLoader(training_data, batch_size = 4, shuffle = True)\n",
        "test_dataloader = DataLoader(test_data, batch_size = 4, shuffle = True)\n",
        "validation_dataloader = DataLoader(validation_data, batch_size = 4, shuffle = True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "k-4rwOY43AzL"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class CNN(nn.Module):   \n",
        "    def __init__(self):\n",
        "        super(CNN, self).__init__()\n",
        "        self.conv1 = nn.Conv3d(1,4,2,2)\n",
        "        self.pool = nn.MaxPool3d(2,2)\n",
        "        self.conv2 = nn.Conv3d(4,16,22)\n",
        "        self.conv3 = nn.Conv3d(16,64,2,2)\n",
        "        self.conv4 = nn.Conv3d(64,256,2,2)\n",
        "        self.fc1 = nn.Linear(256,64)\n",
        "        self.fc2 = nn.Linear(64,16)\n",
        "        self.fc3 = nn.Linear(16,2)\n",
        "\n",
        "    # Defining the forward pass    \n",
        "    def forward(self, x):\n",
        "        x = self.pool(F.leaky_relu(self.conv1(x)))\n",
        "        x = self.pool(F.leaky_relu(self.conv2(x)))\n",
        "        x = self.pool(F.leaky_relu(self.conv3(x)))\n",
        "        x = self.pool(F.leaky_relu(self.conv4(x)))\n",
        "        x = x.view(-1, 256)\n",
        "        x = F.leaky_relu(self.fc1(x))\n",
        "        x = F.leaky_relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        # return F.leaky_relu(x)\n",
        "        return x\n",
        "  \n",
        "model = CNN().to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6tmjVAKQ3WVS",
        "outputId": "0f7675c8-993e-49ef-b41a-398ec4681144"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv3d-1      [4, 4, 132, 132, 132]              36\n",
            "         MaxPool3d-2         [4, 4, 66, 66, 66]               0\n",
            "            Conv3d-3        [4, 16, 45, 45, 45]         681,488\n",
            "         MaxPool3d-4        [4, 16, 22, 22, 22]               0\n",
            "            Conv3d-5        [4, 64, 11, 11, 11]           8,256\n",
            "         MaxPool3d-6           [4, 64, 5, 5, 5]               0\n",
            "            Conv3d-7          [4, 256, 2, 2, 2]         131,328\n",
            "         MaxPool3d-8          [4, 256, 1, 1, 1]               0\n",
            "            Linear-9                    [4, 64]          16,448\n",
            "           Linear-10                    [4, 16]           1,040\n",
            "           Linear-11                     [4, 2]              34\n",
            "================================================================\n",
            "Total params: 838,630\n",
            "Trainable params: 838,630\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 280.76\n",
            "Forward/backward pass size (MB): 368.46\n",
            "Params size (MB): 3.20\n",
            "Estimated Total Size (MB): 652.42\n",
            "----------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "from torchsummary import summary\n",
        "summary(model, (1,264,264,264), batch_size = 4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "Q8XutHXe3vOx"
      },
      "outputs": [],
      "source": [
        "# loss and optimizer\n",
        "learning_rate = 0.001\n",
        "criterion = nn.BCEWithLogitsLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr = learning_rate)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rqMifNHS4p7m",
        "outputId": "c9230f13-acb8-4100-a681-810bcd3fb6d8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training for epoch 1\n",
            "=============================================\n",
            "Number of samples completed after 1 batches = 4\n",
            "Loss of batch 1 = 0.67\n",
            "Total training loss after batch 1 = 0.67\n",
            "Number of samples completed after 2 batches = 8\n",
            "Loss of batch 2 = 0.70\n",
            "Total training loss after batch 2 = 1.38\n",
            "Number of samples completed after 3 batches = 12\n",
            "Loss of batch 3 = 0.64\n",
            "Total training loss after batch 3 = 2.02\n",
            "Number of samples completed after 4 batches = 16\n",
            "Loss of batch 4 = 0.70\n",
            "Total training loss after batch 4 = 2.72\n",
            "Number of samples completed after 5 batches = 20\n",
            "Loss of batch 5 = 0.70\n",
            "Total training loss after batch 5 = 3.42\n",
            "Number of samples completed after 6 batches = 24\n",
            "Loss of batch 6 = 0.65\n",
            "Total training loss after batch 6 = 4.07\n",
            "Number of samples completed after 7 batches = 28\n",
            "Loss of batch 7 = 0.70\n",
            "Total training loss after batch 7 = 4.77\n",
            "Epoch 1/1, step 7/14, loss = 0.6974\n",
            "Number of samples completed after 8 batches = 32\n",
            "Loss of batch 8 = 0.67\n",
            "Total training loss after batch 8 = 5.44\n",
            "Number of samples completed after 9 batches = 36\n",
            "Loss of batch 9 = 0.60\n",
            "Total training loss after batch 9 = 6.04\n",
            "Number of samples completed after 10 batches = 40\n",
            "Loss of batch 10 = 0.60\n",
            "Total training loss after batch 10 = 6.63\n",
            "Number of samples completed after 11 batches = 44\n",
            "Loss of batch 11 = 0.62\n",
            "Total training loss after batch 11 = 7.25\n",
            "Number of samples completed after 12 batches = 48\n",
            "Loss of batch 12 = 0.69\n",
            "Total training loss after batch 12 = 7.94\n",
            "Number of samples completed after 13 batches = 52\n",
            "Loss of batch 13 = 0.64\n",
            "Total training loss after batch 13 = 8.58\n",
            "Number of samples completed after 14 batches = 56\n",
            "Loss of batch 14 = 0.96\n",
            "Total training loss after batch 14 = 9.54\n",
            "Epoch 1/1, step 14/14, loss = 0.9551\n",
            "Training loss array at end of epoch 1: [9.535510957241058]. Total number of images used = 56\n",
            "Finished training for epoch 1\n",
            "Validation for epoch 1\n",
            "=============================================\n",
            "Accuracy on validation set for epoch 1 = 50.0%\n",
            "Finished validation for epoch 1\n",
            "=============================================\n",
            "FINISHED TRAINING\n",
            "Training losses = [9.535510957241058]\n",
            "Average training losses = [0.1702769813793046]\n",
            "Validation losses = [2.1054847240448]\n",
            "Accuracy on training set = 66.7%\n"
          ]
        }
      ],
      "source": [
        "#training_loop\n",
        "num_epochs = 1\n",
        "n_total_steps = len(train_dataloader)\n",
        "train_loss = []\n",
        "valid_loss = []\n",
        "avg_train_loss = []\n",
        "avg_valid_loss = []\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "  # ======================================= TRAINING LOOP ======================================\n",
        "  epoch_train_loss = 0 # will be used for plotting test vs valid loss curves\n",
        "  n_training_samples = 0\n",
        "\n",
        "  print(f'Training for epoch {epoch+1}')\n",
        "  print('=============================================')\n",
        "  \n",
        "\n",
        "  for i, (images, labels) in enumerate(train_dataloader):\n",
        "    # Reformatting input images to have 5 dimensions and casting to a float\n",
        "    images = reshape(images, (images.shape[0],1 ,264,264,264))\n",
        "    images = images.float()\n",
        "\n",
        "\n",
        "    # turning labels of size one to one-hot labels \n",
        "    # e.g labels = (1,0,0,1) --> hot_labels [(0,1), (1,0), (1,0), 0,1]\n",
        "    # This is need because nn.BCELogitsWithLoss() expects inputs of this format\n",
        "    hot_labels = torch.empty((images.shape[0], 2))\n",
        "    for index in range(len(labels)):\n",
        "          if labels[index] == 0 :\n",
        "            hot_labels[index,0] = 1\n",
        "            hot_labels[index,1] = 0\n",
        "          elif labels[index] == 1 :\n",
        "            hot_labels[index,0] = 0\n",
        "            hot_labels[index,1] = 1\n",
        "    \n",
        "    \n",
        "    # Send images and one-hot labels to the device (cuda/GPU)\n",
        "    images = images.to(device)\n",
        "    hot_labels = hot_labels.to(device)\n",
        "\n",
        "\n",
        "    # Forward pass\n",
        "    outputs = model(images)\n",
        "    loss = criterion(outputs, hot_labels)\n",
        "    \n",
        "\n",
        "    # Backwards pass\n",
        "    optimizer.zero_grad() # Clear gradients before \n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    # Add the number of images in this batch to n_training_samples which will\n",
        "    # be used when calculating the average loss per image in the training set\n",
        "    n_training_samples += labels.shape[0]\n",
        "    print(f'Number of samples completed after {i+1} batches = {n_training_samples}')\n",
        "    \n",
        "\n",
        "    # Updating the total training loss of this epoch\n",
        "    # Printing loss for current batch and the new updated total\n",
        "    # training loss for this epoch\n",
        "    print(f'Loss of batch {i+1} = {loss.item():.2f}')\n",
        "    epoch_train_loss += loss.item()\n",
        "    print(f'Total training loss after batch {i+1} = {epoch_train_loss:.2f}')\n",
        "    \n",
        "\n",
        "    # Print a progress statement to ensure the network is running\n",
        "    if (i+1)%7 == 0 :\n",
        "      print(f'Epoch {epoch+1}/{num_epochs}, step {i+1}/{n_total_steps}, loss = {loss.item():.4f}')\n",
        "  \n",
        "  # Append the train_loss list with the total training loss for this epoch\n",
        "  train_loss.append(epoch_train_loss)\n",
        "\n",
        "  # Append the avg_train_loss list with the average training loss of this epoch\n",
        "  avg_train_loss.append(epoch_train_loss/n_training_samples)\n",
        "  \n",
        "  print(f'Training loss array at end of epoch {epoch + 1}: {train_loss}. Total number of images used = {n_training_samples}')\n",
        "  print(f'Finished training for epoch {epoch+1}')\n",
        "  \n",
        "  #================================================ VALIDATION LOOP =================================================\n",
        "  print(f'Validation for epoch {epoch+1}')\n",
        "  print('=============================================')\n",
        "  with torch.no_grad():\n",
        "    valid_epoch_loss = 0\n",
        "    n_valid_correct = 0\n",
        "    n_valid_samples = 0\n",
        "    for images, labels in validation_dataloader :\n",
        "      images = images = reshape(images, (images.shape[0],1 ,264,264,264))\n",
        "      images = images.float()\n",
        "      hot_labels = torch.empty((images.shape[0], 2))\n",
        "      #print(new_labels.shape)\n",
        "      for index in range(len(labels)):\n",
        "          if labels[index] == 0 :\n",
        "            hot_labels[index,0] = 1\n",
        "            hot_labels[index,1] = 0\n",
        "          elif labels[index] == 1 :\n",
        "            hot_labels[index,0] = 0\n",
        "            hot_labels[index,1] = 1\n",
        "      images = images.to(device)\n",
        "      hot_labels = hot_labels.to(device)\n",
        "      outputs = model(images)\n",
        "      # calculate loss of validation set\n",
        "      loss = criterion(outputs, hot_labels)\n",
        "      valid_epoch_loss += loss.item()\n",
        "\n",
        "      # max returns (value, index) \n",
        "      _,predictions = torch.max(outputs, 1)\n",
        "      _,targets = torch.max(hot_labels, 1)\n",
        "      #print(f'predictions: {predictions}')\n",
        "      #print(f'targets: {targets}')\n",
        "      #print(f'correct in this batch: {(predictions == targets).sum().item()}')\n",
        "      n_valid_samples += labels.shape[0]\n",
        "      n_valid_correct += (predictions == targets).sum().item()\n",
        "      #print(f'n_correct = {n_correct}. n_samples = {n_samples}')\n",
        "\n",
        "    valid_loss.append(valid_epoch_loss)\n",
        "    acc = (100*n_valid_correct)/n_valid_samples\n",
        "    print(f'Accuracy on validation set for epoch {epoch+1} = {acc:.1f}%')\n",
        "\n",
        "    print(f'Finished validation for epoch {epoch+1}')\n",
        "    print('=============================================')\n",
        "\n",
        "print('FINISHED TRAINING')\n",
        "print(f'Training losses = {train_loss}')\n",
        "print(f'Average training losses = {avg_train_loss}')\n",
        "print(f'Validation losses = {valid_loss}')\n",
        "#testing\n",
        "with torch.no_grad():\n",
        "    n_correct = 0\n",
        "    n_samples = 0\n",
        "    for images, labels in test_dataloader :\n",
        "      images = images = reshape(images, (images.shape[0],1 ,264,264,264))\n",
        "      images = images.float()\n",
        "      hot_labels = torch.empty((images.shape[0], 2))\n",
        "      #print(new_labels.shape)\n",
        "      for index in range(len(labels)):\n",
        "          if labels[index] == 0 :\n",
        "            hot_labels[index,0] = 1\n",
        "            hot_labels[index,1] = 0\n",
        "          elif labels[index] == 1 :\n",
        "            hot_labels[index,0] = 0\n",
        "            hot_labels[index,1] = 1\n",
        "      images = images.to(device)\n",
        "      hot_labels = hot_labels.to(device)\n",
        "      outputs = model(images)\n",
        "      # max returns (value, index) \n",
        "      _,predictions = torch.max(outputs, 1)\n",
        "      _,targets = torch.max(hot_labels,1)\n",
        "      #print(f'predictions: {predictions}')\n",
        "      #print(f'targets: {targets}')\n",
        "      n_samples += hot_labels.shape[0]\n",
        "      n_correct += (predictions == targets).sum().item()\n",
        "      #print(f'n_correct = {n_correct}. n_samples = {n_samples}')\n",
        "    \n",
        "    acc = (100*n_correct)/n_samples\n",
        "    print(f'Accuracy on training set = {acc:.1f}%')\n",
        "\n",
        "\n",
        "# time renewal\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "CNN4.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOKlySrQ6vOrLGOh+K6EHrA",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}