{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rfarwell/MPhys/blob/main/CNN4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# To do list\n",
        "1. Figure out normalization when creating the datasets\n",
        "2. Get to work with tensorboard to see if weights are changing\n",
        "3. Issue: currently the network reaches approx minimum loss after just 7 batches of 1 epoch. This may be because the network is very simple or other factors."
      ],
      "metadata": {
        "id": "e9Hd9ZIlACIM"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MfWFoJBL2P6A",
        "outputId": "6fd220ee-6d88-4a3d-c961-e18cf5870021"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (1.10.0+cu111)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.7/dist-packages (0.11.1+cu111)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch) (3.10.0.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchvision) (1.19.5)\n",
            "Requirement already satisfied: pillow!=8.3.0,>=5.3.0 in /usr/local/lib/python3.7/dist-packages (from torchvision) (7.1.2)\n",
            "Requirement already satisfied: opencv-contrib-python in /usr/local/lib/python3.7/dist-packages (4.1.2.30)\n",
            "Requirement already satisfied: numpy>=1.14.5 in /usr/local/lib/python3.7/dist-packages (from opencv-contrib-python) (1.19.5)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (1.0.1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn) (1.1.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn) (3.0.0)\n",
            "Requirement already satisfied: numpy>=1.14.6 in /usr/local/lib/python3.7/dist-packages (from scikit-learn) (1.19.5)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn) (1.4.1)\n",
            "Collecting SimpleITK\n",
            "  Downloading SimpleITK-2.1.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (48.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 48.4 MB 2.9 MB/s \n",
            "\u001b[?25hInstalling collected packages: SimpleITK\n",
            "Successfully installed SimpleITK-2.1.1\n"
          ]
        }
      ],
      "source": [
        "!pip install torch torchvision\n",
        "!pip install opencv-contrib-python\n",
        "!pip install scikit-learn\n",
        "!pip install SimpleITK\n",
        "\n",
        "import numpy as np\n",
        "import random\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import SimpleITK as sitk\n",
        "import torch\n",
        "\n",
        "from mpl_toolkits.mplot3d import Axes3D\n",
        "from torch.nn import Module\n",
        "from torch.nn import Conv3d\n",
        "from torch.nn import Linear\n",
        "from torch.nn import MaxPool2d\n",
        "from torch.nn import ReLU\n",
        "from torch.nn import LogSoftmax\n",
        "from torch import flatten\n",
        "from torch import nn\n",
        "from torch import reshape\n",
        "from torch.utils.data import Dataset\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import transforms\n",
        "from torchvision import datasets\n",
        "from torch.optim import Adam\n",
        "import torchvision.models as models\n",
        "from torch.autograd import Variable"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "95pHZBRQ2Zbl",
        "outputId": "349b4e44-5d1e-451c-8733-5fbdb4f92f85"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j-zAX1vZ2bSU",
        "outputId": "b8c262ea-6485-4735-a1a9-133c8db34e4c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using cuda device\n",
            "/content/gdrive/MyDrive/MPhys/Data/COLAB-Clinical-Data.csv\n"
          ]
        }
      ],
      "source": [
        "# Connect to GPU is available\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "print(f'Using {device} device')\n",
        "# /content/gdrive/MyDrive/MPhys/Data/COLAB-Clinical-Data.csv\n",
        "# Specify project folder location\n",
        "project_folder = \"/content/gdrive/MyDrive/MPhys/Data\"\n",
        "clinical_data_filename = \"COLAB-Clinical-Data.csv\"\n",
        "print(os.path.join(project_folder, clinical_data_filename))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7HU0Og4e2k_k",
        "outputId": "2374e5e2-3e8e-4c59-c143-21ea0e775522"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Length of metadata array is 100\n",
            "Dead counter after 547.5 days: 60\n",
            "Alive counter after 547.5 days: 40\n",
            "No-info counter after 547.5 days: 0\n",
            "The alive and dead arrays have been sorted (randomly) so that they are both of length 40\n",
            "56\n"
          ]
        }
      ],
      "source": [
        "def equalise_array_lengths(array_1, array_2) :\n",
        "  \"\"\"\n",
        "  This functions takes in the arguments of two lists and makes sure they are returned as the same length.\n",
        "\n",
        "  Rory Farwell 02/12/2021\n",
        "  \"\"\"\n",
        "  # output_array = []\n",
        "  if len(array_1) > len(array_2) :\n",
        "    array_1 = array_1[:len(array_2)]\n",
        "  elif len(array_1) < len(array_2) :\n",
        "    array_2 = array_2[:len(array_1)]\n",
        "  #print(np.vstack((array_1, array_2)))\n",
        "  # output_array.append(array_1)\n",
        "  # output_array.append(array_2)\n",
        "  return (array_1, array_2)\n",
        "\n",
        "def remove_same_elements(small_array, long_array) :\n",
        "  \"\"\"\n",
        "  For use in the context, all the elements in small_array come from long_array.\n",
        "  This function will remove all of the elements used in small_array from_long_array.  \n",
        "  \"\"\"\n",
        "  for element in small_array :\n",
        "    long_array.remove(element)\n",
        "  return long_array\n",
        "\n",
        "def create_subgroup(input_array, original_array_length, desired_percentage) :\n",
        "  \"\"\"\n",
        "  This function outputs a subgroup array (e.g. training array) using a specified output array name,\n",
        "  input array and percentage length\n",
        "  \"\"\"\n",
        "  desired_length = int(original_array_length * desired_percentage)\n",
        "  output_array = random.sample(input_array, desired_length)\n",
        "  return output_array\n",
        "  \n",
        "\n",
        "# Open the metadata.csv file, convert to an array, and remove column headers\n",
        "metadata_file = os.path.join(project_folder, clinical_data_filename)\n",
        "metadata = np.genfromtxt(metadata_file, comments = '%', dtype=\"str\", delimiter=\",\")\n",
        "print(f\"Length of metadata array is {len(metadata)}\")\n",
        "\n",
        "outcome_type = 1 #int(input(\"Select which outcome you are aiming to predict \\n(1=Locoregional, 2=Distant Metastasis, 3=Death):\"))\n",
        "check_day = 3000 #int(input(\"Select the number of days at which to check for event:\"))\n",
        "which_patients = 1 #int(input(\"Do you want to include patients whose last follow up is before the check day? (no = 0, yes = 1):\"))\n",
        "patient_with_event = []\n",
        "patient_no_event = []\n",
        "outcomes_train = []\n",
        "outcomes_test = []\n",
        "images = []\n",
        "\n",
        "check_day = 365 * 1.5 # This is defining the timeframe for which our CNN will consider the binary output (in days)\n",
        "\n",
        "patient_IDs = metadata[:,0]\n",
        "time_markers = metadata[:,8]\n",
        "dead_statuses = metadata[:,9]\n",
        "\n",
        "time_markers = time_markers.astype(np.float32)\n",
        "dead_statuses = dead_statuses.astype(np.float32)\n",
        "\n",
        "\n",
        "check_day_dead_statuses = []\n",
        "\n",
        "counter = 0 \n",
        "\n",
        "dead_counter = 0\n",
        "alive_counter = 0\n",
        "no_info_counter = 0\n",
        "\n",
        "dead_patient_array = []\n",
        "alive_patient_array = []\n",
        "\n",
        "for i in range(len(dead_statuses)) :\n",
        "  # counter+=1\n",
        "  # print(counter)\n",
        "  temp_dead_status = dead_statuses[i]\n",
        "  #print(temp_dead_status)\n",
        "  temp_time_marker = time_markers[i]\n",
        "  #print(temp_time_marker)\n",
        "  if temp_dead_status == 1 : #if the patient is dead\n",
        "    #print('y')\n",
        "    if temp_time_marker < check_day :\n",
        "      check_day_dead_statuses.append(1) #confirms that the patient was dead after time 'check_day'\n",
        "      dead_patient_array.append([patient_IDs[i], 1])\n",
        "      dead_counter += 1\n",
        "      continue\n",
        "    elif temp_time_marker > check_day :\n",
        "      check_day_dead_statuses.append(0)\n",
        "      alive_patient_array.append([patient_IDs[i], 0])\n",
        "      alive_counter += 1\n",
        "      continue\n",
        "  elif temp_dead_status == 0 : #if the patient is alive\n",
        "    #print('n')\n",
        "    if temp_time_marker < check_day :\n",
        "      no_info_counter += 1\n",
        "      continue\n",
        "    elif temp_time_marker > check_day :\n",
        "      check_day_dead_statuses.append(0)\n",
        "      alive_patient_array.append([patient_IDs[i], 0])\n",
        "      alive_counter += 1\n",
        "      continue\n",
        "print(f\"Dead counter after {check_day} days: {dead_counter}\")\n",
        "print(f\"Alive counter after {check_day} days: {alive_counter}\")\n",
        "print(f\"No-info counter after {check_day} days: {no_info_counter}\")\n",
        "\n",
        "# print(len(dead_patient_array), dead_patient_array)\n",
        "# print(len(alive_patient_array), alive_patient_array)\n",
        "\n",
        "training_array = []\n",
        "testing_array = []\n",
        "validation_array = []\n",
        "\n",
        "random.shuffle(dead_patient_array) #shuffling both arrays to ensure random selection of patient data\n",
        "random.shuffle(alive_patient_array)\n",
        "\n",
        "# equalising the length of the 'dead' and 'alive' arrays so that we can ensure optimum training proportions\n",
        "new_dead_patient_array = equalise_array_lengths(dead_patient_array, alive_patient_array)[0]\n",
        "new_alive_patient_array = equalise_array_lengths(dead_patient_array, alive_patient_array)[1]\n",
        "print(f\"The alive and dead arrays have been sorted (randomly) so that they are both of length {len(new_dead_patient_array)}\")\n",
        "\n",
        "# print(new_dead_patient_array)\n",
        "# print(new_alive_patient_array)\n",
        "# print(len(new_dead_patient_array))\n",
        "# print(len(new_alive_patient_array))\n",
        "\n",
        "equalised_array_length = len(new_alive_patient_array)\n",
        "\n",
        "train_patients_dead = create_subgroup(new_dead_patient_array, equalised_array_length, 0.7)\n",
        "train_patients_alive = create_subgroup(new_alive_patient_array, equalised_array_length, 0.7)\n",
        "# print(len(train_patients_dead))\n",
        "# print(len(train_patients_alive))\n",
        "\n",
        "new_dead_patient_array = remove_same_elements(train_patients_dead, new_dead_patient_array)\n",
        "new_alive_patient_array = remove_same_elements(train_patients_alive, new_alive_patient_array)\n",
        "# print(len(new_dead_patient_array))\n",
        "# print(len(new_alive_patient_array))\n",
        "\n",
        "test_patients_dead = create_subgroup(new_dead_patient_array, equalised_array_length, 0.15)\n",
        "test_patients_alive = create_subgroup(new_alive_patient_array, equalised_array_length, 0.15)\n",
        "# print(len(test_patients_dead))\n",
        "# print(len(test_patients_alive))\n",
        "\n",
        "new_dead_patient_array = remove_same_elements(test_patients_dead, new_dead_patient_array)\n",
        "new_alive_patient_array = remove_same_elements(test_patients_alive, new_alive_patient_array)\n",
        "# print(len(new_dead_patient_array))\n",
        "# print(len(new_alive_patient_array))\n",
        "\n",
        "validate_patients_dead = create_subgroup(new_dead_patient_array, equalised_array_length, 0.15)\n",
        "validate_patients_alive = create_subgroup(new_alive_patient_array, equalised_array_length, 0.15)\n",
        "# print(len(validate_patients_dead))\n",
        "# print(len(validate_patients_alive))\n",
        "\n",
        "new_dead_patient_array = remove_same_elements(validate_patients_dead, new_dead_patient_array)\n",
        "new_alive_patient_array = remove_same_elements(validate_patients_alive, new_alive_patient_array)\n",
        "# print(len(new_dead_patient_array))\n",
        "# print(len(new_alive_patient_array))\n",
        "\n",
        "\n",
        "outcomes_train = train_patients_dead + train_patients_alive\n",
        "outcomes_test = test_patients_dead + test_patients_alive\n",
        "outcomes_validate = validate_patients_dead + validate_patients_alive\n",
        "\n",
        "print(len(outcomes_train))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qt8pEoBq20QD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b39dadaa-03f5-46d8-bd88-021d44056739"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(-1024., dtype=torch.float64)\n",
            "tensor(-1005.5188, dtype=torch.float64) tensor(138.7543, dtype=torch.float64)\n",
            "1\n",
            "tensor(-1024.)\n",
            "tensor(-1021.0183) tensor(56.1689)\n",
            "1\n",
            "tensor(-0.1332, dtype=torch.float64)\n",
            "tensor(5.5213e-17, dtype=torch.float64) tensor(1.0000, dtype=torch.float64)\n",
            "1\n",
            "tensor(-0.0531)\n",
            "tensor(1.9105e-07) tensor(1.)\n",
            "1\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "from torchvision.io import read_image\n",
        "\n",
        "# Normalize class added at 10pm 12/12/2021\n",
        "class Normalize():\n",
        "  def __init__(self):\n",
        "    pass\n",
        "  \n",
        "  # def __call__(self, sample):\n",
        "  #   inputs, targets = sample\n",
        "  #   inputs = transforms.Normalize(mean = 0.5, std = 0.5)\n",
        "  #   return inputs, targets\n",
        "  def __call__(self,vol):\n",
        "    vol =(vol-vol.mean())/vol.std()\n",
        "    return vol\n",
        "\n",
        "transform = transforms.Compose(\n",
        "    [transforms.ToTensor(), transforms.Normalize(mean = 0.5, std = 0.5)] #added at 10:31pm 13/12/2021 to normalize the inputs\n",
        ")\n",
        "\n",
        "transform = transforms.Compose(\n",
        "    [transforms.ToTensor(), Normalize() ] #added at 11:00pm 13/12/2021 to normalize the inputs. THIS NORMALIZES to mean = 0 and std = -1\n",
        ")\n",
        "\n",
        "\n",
        "class ImageDataset(Dataset) :\n",
        "  def __init__(self, annotations, img_dir, transform = transform, target_transform = None) :\n",
        "    self.img_labels = annotations\n",
        "    self.img_dir = img_dir\n",
        "    self.transform = transform\n",
        "    self.target_transform = target_transform\n",
        "\n",
        "  def __len__(self) :\n",
        "    return len(self.img_labels)\n",
        "\n",
        "  def __getitem__(self,idx) :\n",
        "    img_path = os.path.join(self.img_dir, self.img_labels[idx][0] + \"-GTV-1.nii\" )\n",
        "    image_sitk = sitk.ReadImage(img_path)\n",
        "    image = sitk.GetArrayFromImage(image_sitk)\n",
        "    label = self.img_labels[idx][1]\n",
        "    if self.transform :\n",
        "      image = self.transform(image)\n",
        "    if self.target_transform :\n",
        "      label = self.target_transform(label)\n",
        "    return image,label\n",
        "\n",
        "training_data = ImageDataset(outcomes_train, os.path.join(project_folder, \"Textured_Masks\"), transform = transforms.ToTensor())\n",
        "validation_data = ImageDataset(outcomes_validate, os.path.join(project_folder, \"Textured_Masks\"), transform = transforms.ToTensor())\n",
        "test_data = ImageDataset(outcomes_test, os.path.join(project_folder, \"Textured_Masks\"), transform = transforms.ToTensor())\n",
        "print(training_data[0][0][0][0][0])\n",
        "print(training_data[0][0].mean(), training_data[0][0].std())\n",
        "print(training_data[0][1])\n",
        "print(training_data[1][0][0][0][0])\n",
        "print(training_data[1][0].mean(), training_data[1][0].std())\n",
        "print(training_data[1][1])\n",
        "\n",
        "training_data = ImageDataset(outcomes_train, os.path.join(project_folder, \"Textured_Masks\"), transform = transform)\n",
        "validation_data = ImageDataset(outcomes_validate, os.path.join(project_folder, \"Textured_Masks\"), transform = transform)\n",
        "test_data = ImageDataset(outcomes_test, os.path.join(project_folder, \"Textured_Masks\"), transform = transform) \n",
        "print(training_data[0][0][0][0][0])\n",
        "print(training_data[0][0].mean(), training_data[0][0].std())\n",
        "print(training_data[0][1])\n",
        "print(training_data[1][0][0][0][0])\n",
        "print(training_data[1][0].mean(), training_data[1][0].std())\n",
        "print(training_data[1][1])\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0KfrxkyK2-sj"
      },
      "outputs": [],
      "source": [
        "train_dataloader = DataLoader(training_data, batch_size = 4, shuffle = True)\n",
        "test_dataloader = DataLoader(test_data, batch_size = 4, shuffle = True)\n",
        "validation_dataloader = DataLoader(validation_data, batch_size = 4, shuffle = True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k-4rwOY43AzL"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class CNN(nn.Module):   \n",
        "    def __init__(self):\n",
        "        super(CNN, self).__init__()\n",
        "        self.conv1 = nn.Conv3d(1,4,2,2)\n",
        "        self.pool = nn.MaxPool3d(2,2)\n",
        "        self.conv2 = nn.Conv3d(4,16,22)\n",
        "        self.conv3 = nn.Conv3d(16,64,2,2)\n",
        "        self.conv4 = nn.Conv3d(64,256,2,2)\n",
        "        self.fc1 = nn.Linear(256,64)\n",
        "        self.fc2 = nn.Linear(64,16)\n",
        "        self.fc3 = nn.Linear(16,2)\n",
        "\n",
        "    # Defining the forward pass    \n",
        "    def forward(self, x):\n",
        "        x = self.pool(F.leaky_relu(self.conv1(x)))\n",
        "        x = self.pool(F.leaky_relu(self.conv2(x)))\n",
        "        x = self.pool(F.leaky_relu(self.conv3(x)))\n",
        "        x = self.pool(F.leaky_relu(self.conv4(x)))\n",
        "        x = x.view(-1, 256)\n",
        "        x = F.leaky_relu(self.fc1(x))\n",
        "        x = F.leaky_relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        # return F.leaky_relu(x)\n",
        "        return x\n",
        "  \n",
        "model = CNN().to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6tmjVAKQ3WVS",
        "outputId": "b2ce640b-58ef-4c8c-89f0-f264ce266fd4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv3d-1      [4, 4, 132, 132, 132]              36\n",
            "         MaxPool3d-2         [4, 4, 66, 66, 66]               0\n",
            "            Conv3d-3        [4, 16, 45, 45, 45]         681,488\n",
            "         MaxPool3d-4        [4, 16, 22, 22, 22]               0\n",
            "            Conv3d-5        [4, 64, 11, 11, 11]           8,256\n",
            "         MaxPool3d-6           [4, 64, 5, 5, 5]               0\n",
            "            Conv3d-7          [4, 256, 2, 2, 2]         131,328\n",
            "         MaxPool3d-8          [4, 256, 1, 1, 1]               0\n",
            "            Linear-9                    [4, 64]          16,448\n",
            "           Linear-10                    [4, 16]           1,040\n",
            "           Linear-11                     [4, 2]              34\n",
            "================================================================\n",
            "Total params: 838,630\n",
            "Trainable params: 838,630\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 280.76\n",
            "Forward/backward pass size (MB): 368.46\n",
            "Params size (MB): 3.20\n",
            "Estimated Total Size (MB): 652.42\n",
            "----------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "from torchsummary import summary\n",
        "summary(model, (1,264,264,264), batch_size = 4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q8XutHXe3vOx"
      },
      "outputs": [],
      "source": [
        "# loss and optimizer\n",
        "learning_rate = 0.001\n",
        "criterion = nn.BCEWithLogitsLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr = learning_rate)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rqMifNHS4p7m",
        "outputId": "6e152a08-08bb-4196-f8fc-67dfa4e12335"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training for epoch 1\n",
            "=============================================\n",
            "Epoch 1/20, step 7/14, loss = 0.7126\n",
            "Epoch 1/20, step 14/14, loss = 0.7170\n",
            "Finished training for epoch 1\n",
            "Validation for epoch 1\n",
            "=============================================\n",
            "predictions: tensor([0, 0, 1, 1], device='cuda:0')\n",
            "targets: tensor([0, 0, 1, 1], device='cuda:0')\n",
            "correct in this batch: 4\n",
            "n_correct = 4. n_samples = 4\n",
            "predictions: tensor([1, 1, 1, 0], device='cuda:0')\n",
            "targets: tensor([1, 0, 1, 0], device='cuda:0')\n",
            "correct in this batch: 3\n",
            "n_correct = 7. n_samples = 8\n",
            "predictions: tensor([1, 0, 1, 0], device='cuda:0')\n",
            "targets: tensor([0, 1, 0, 1], device='cuda:0')\n",
            "correct in this batch: 0\n",
            "n_correct = 7. n_samples = 12\n",
            "Accuracy on validation set for epoch 1 = 58.3%\n",
            "Finished validation for epoch 1\n",
            "=============================================\n",
            "Training for epoch 2\n",
            "=============================================\n",
            "Epoch 2/20, step 7/14, loss = 0.6607\n",
            "Epoch 2/20, step 14/14, loss = 0.6294\n",
            "Finished training for epoch 2\n",
            "Validation for epoch 2\n",
            "=============================================\n",
            "predictions: tensor([1, 0, 1, 0], device='cuda:0')\n",
            "targets: tensor([1, 0, 1, 0], device='cuda:0')\n",
            "correct in this batch: 4\n",
            "n_correct = 4. n_samples = 4\n",
            "predictions: tensor([0, 1, 0, 0], device='cuda:0')\n",
            "targets: tensor([0, 1, 1, 1], device='cuda:0')\n",
            "correct in this batch: 2\n",
            "n_correct = 6. n_samples = 8\n",
            "predictions: tensor([1, 1, 0, 0], device='cuda:0')\n",
            "targets: tensor([0, 0, 1, 0], device='cuda:0')\n",
            "correct in this batch: 1\n",
            "n_correct = 7. n_samples = 12\n",
            "Accuracy on validation set for epoch 2 = 58.3%\n",
            "Finished validation for epoch 2\n",
            "=============================================\n",
            "Training for epoch 3\n",
            "=============================================\n",
            "Epoch 3/20, step 7/14, loss = 0.7810\n",
            "Epoch 3/20, step 14/14, loss = 0.7110\n",
            "Finished training for epoch 3\n",
            "Validation for epoch 3\n",
            "=============================================\n",
            "predictions: tensor([1, 1, 1, 1], device='cuda:0')\n",
            "targets: tensor([1, 1, 0, 0], device='cuda:0')\n",
            "correct in this batch: 2\n",
            "n_correct = 2. n_samples = 4\n",
            "predictions: tensor([1, 0, 0, 1], device='cuda:0')\n",
            "targets: tensor([0, 1, 0, 1], device='cuda:0')\n",
            "correct in this batch: 2\n",
            "n_correct = 4. n_samples = 8\n",
            "predictions: tensor([0, 0, 0, 0], device='cuda:0')\n",
            "targets: tensor([1, 1, 0, 0], device='cuda:0')\n",
            "correct in this batch: 2\n",
            "n_correct = 6. n_samples = 12\n",
            "Accuracy on validation set for epoch 3 = 50.0%\n",
            "Finished validation for epoch 3\n",
            "=============================================\n",
            "Training for epoch 4\n",
            "=============================================\n",
            "Epoch 4/20, step 7/14, loss = 0.4702\n",
            "Epoch 4/20, step 14/14, loss = 0.5088\n",
            "Finished training for epoch 4\n",
            "Validation for epoch 4\n",
            "=============================================\n",
            "predictions: tensor([1, 1, 1, 1], device='cuda:0')\n",
            "targets: tensor([0, 0, 1, 1], device='cuda:0')\n",
            "correct in this batch: 2\n",
            "n_correct = 2. n_samples = 4\n",
            "predictions: tensor([1, 1, 1, 1], device='cuda:0')\n",
            "targets: tensor([1, 1, 0, 0], device='cuda:0')\n",
            "correct in this batch: 2\n",
            "n_correct = 4. n_samples = 8\n",
            "predictions: tensor([0, 1, 0, 0], device='cuda:0')\n",
            "targets: tensor([1, 0, 1, 0], device='cuda:0')\n",
            "correct in this batch: 1\n",
            "n_correct = 5. n_samples = 12\n",
            "Accuracy on validation set for epoch 4 = 41.7%\n",
            "Finished validation for epoch 4\n",
            "=============================================\n",
            "Training for epoch 5\n",
            "=============================================\n",
            "Epoch 5/20, step 7/14, loss = 0.6163\n",
            "Epoch 5/20, step 14/14, loss = 0.4885\n",
            "Finished training for epoch 5\n",
            "Validation for epoch 5\n",
            "=============================================\n",
            "predictions: tensor([1, 0, 1, 1], device='cuda:0')\n",
            "targets: tensor([0, 0, 1, 0], device='cuda:0')\n",
            "correct in this batch: 2\n",
            "n_correct = 2. n_samples = 4\n",
            "predictions: tensor([0, 1, 1, 0], device='cuda:0')\n",
            "targets: tensor([1, 1, 0, 1], device='cuda:0')\n",
            "correct in this batch: 1\n",
            "n_correct = 3. n_samples = 8\n",
            "predictions: tensor([1, 1, 0, 1], device='cuda:0')\n",
            "targets: tensor([0, 1, 0, 1], device='cuda:0')\n",
            "correct in this batch: 3\n",
            "n_correct = 6. n_samples = 12\n",
            "Accuracy on validation set for epoch 5 = 50.0%\n",
            "Finished validation for epoch 5\n",
            "=============================================\n",
            "Training for epoch 6\n",
            "=============================================\n",
            "Epoch 6/20, step 7/14, loss = 0.6338\n",
            "Epoch 6/20, step 14/14, loss = 0.4293\n",
            "Finished training for epoch 6\n",
            "Validation for epoch 6\n",
            "=============================================\n",
            "predictions: tensor([1, 0, 0, 1], device='cuda:0')\n",
            "targets: tensor([1, 1, 1, 0], device='cuda:0')\n",
            "correct in this batch: 1\n",
            "n_correct = 1. n_samples = 4\n",
            "predictions: tensor([1, 1, 1, 1], device='cuda:0')\n",
            "targets: tensor([0, 1, 1, 0], device='cuda:0')\n",
            "correct in this batch: 2\n",
            "n_correct = 3. n_samples = 8\n",
            "predictions: tensor([1, 1, 0, 1], device='cuda:0')\n",
            "targets: tensor([0, 0, 0, 1], device='cuda:0')\n",
            "correct in this batch: 2\n",
            "n_correct = 5. n_samples = 12\n",
            "Accuracy on validation set for epoch 6 = 41.7%\n",
            "Finished validation for epoch 6\n",
            "=============================================\n",
            "Training for epoch 7\n",
            "=============================================\n",
            "Epoch 7/20, step 7/14, loss = 0.1186\n",
            "Epoch 7/20, step 14/14, loss = 0.1314\n",
            "Finished training for epoch 7\n",
            "Validation for epoch 7\n",
            "=============================================\n",
            "predictions: tensor([1, 1, 0, 0], device='cuda:0')\n",
            "targets: tensor([0, 0, 0, 1], device='cuda:0')\n",
            "correct in this batch: 1\n",
            "n_correct = 1. n_samples = 4\n",
            "predictions: tensor([0, 0, 0, 1], device='cuda:0')\n",
            "targets: tensor([1, 1, 1, 1], device='cuda:0')\n",
            "correct in this batch: 1\n",
            "n_correct = 2. n_samples = 8\n",
            "predictions: tensor([0, 0, 1, 0], device='cuda:0')\n",
            "targets: tensor([0, 0, 0, 1], device='cuda:0')\n",
            "correct in this batch: 2\n",
            "n_correct = 4. n_samples = 12\n",
            "Accuracy on validation set for epoch 7 = 33.3%\n",
            "Finished validation for epoch 7\n",
            "=============================================\n",
            "Training for epoch 8\n",
            "=============================================\n",
            "Epoch 8/20, step 7/14, loss = 0.2664\n",
            "Epoch 8/20, step 14/14, loss = 1.0329\n",
            "Finished training for epoch 8\n",
            "Validation for epoch 8\n",
            "=============================================\n",
            "predictions: tensor([0, 0, 0, 0], device='cuda:0')\n",
            "targets: tensor([0, 0, 0, 0], device='cuda:0')\n",
            "correct in this batch: 4\n",
            "n_correct = 4. n_samples = 4\n",
            "predictions: tensor([0, 0, 0, 0], device='cuda:0')\n",
            "targets: tensor([1, 1, 1, 0], device='cuda:0')\n",
            "correct in this batch: 1\n",
            "n_correct = 5. n_samples = 8\n",
            "predictions: tensor([0, 0, 0, 0], device='cuda:0')\n",
            "targets: tensor([1, 1, 0, 1], device='cuda:0')\n",
            "correct in this batch: 1\n",
            "n_correct = 6. n_samples = 12\n",
            "Accuracy on validation set for epoch 8 = 50.0%\n",
            "Finished validation for epoch 8\n",
            "=============================================\n",
            "Training for epoch 9\n",
            "=============================================\n",
            "Epoch 9/20, step 7/14, loss = 0.0981\n",
            "Epoch 9/20, step 14/14, loss = 0.2529\n",
            "Finished training for epoch 9\n",
            "Validation for epoch 9\n",
            "=============================================\n",
            "predictions: tensor([0, 0, 0, 0], device='cuda:0')\n",
            "targets: tensor([0, 1, 1, 1], device='cuda:0')\n",
            "correct in this batch: 1\n",
            "n_correct = 1. n_samples = 4\n",
            "predictions: tensor([1, 0, 0, 0], device='cuda:0')\n",
            "targets: tensor([0, 0, 0, 1], device='cuda:0')\n",
            "correct in this batch: 2\n",
            "n_correct = 3. n_samples = 8\n",
            "predictions: tensor([0, 1, 0, 1], device='cuda:0')\n",
            "targets: tensor([1, 1, 0, 0], device='cuda:0')\n",
            "correct in this batch: 2\n",
            "n_correct = 5. n_samples = 12\n",
            "Accuracy on validation set for epoch 9 = 41.7%\n",
            "Finished validation for epoch 9\n",
            "=============================================\n",
            "Training for epoch 10\n",
            "=============================================\n",
            "Epoch 10/20, step 7/14, loss = 0.0116\n",
            "Epoch 10/20, step 14/14, loss = 0.0524\n",
            "Finished training for epoch 10\n",
            "Validation for epoch 10\n",
            "=============================================\n",
            "predictions: tensor([1, 1, 0, 1], device='cuda:0')\n",
            "targets: tensor([0, 1, 0, 0], device='cuda:0')\n",
            "correct in this batch: 2\n",
            "n_correct = 2. n_samples = 4\n",
            "predictions: tensor([0, 0, 0, 0], device='cuda:0')\n",
            "targets: tensor([1, 0, 1, 0], device='cuda:0')\n",
            "correct in this batch: 2\n",
            "n_correct = 4. n_samples = 8\n",
            "predictions: tensor([0, 0, 0, 1], device='cuda:0')\n",
            "targets: tensor([1, 1, 1, 0], device='cuda:0')\n",
            "correct in this batch: 0\n",
            "n_correct = 4. n_samples = 12\n",
            "Accuracy on validation set for epoch 10 = 33.3%\n",
            "Finished validation for epoch 10\n",
            "=============================================\n",
            "Training for epoch 11\n",
            "=============================================\n",
            "Epoch 11/20, step 7/14, loss = 0.0501\n",
            "Epoch 11/20, step 14/14, loss = 0.1817\n",
            "Finished training for epoch 11\n",
            "Validation for epoch 11\n",
            "=============================================\n",
            "predictions: tensor([1, 0, 1, 1], device='cuda:0')\n",
            "targets: tensor([1, 1, 0, 1], device='cuda:0')\n",
            "correct in this batch: 2\n",
            "n_correct = 2. n_samples = 4\n",
            "predictions: tensor([1, 1, 1, 1], device='cuda:0')\n",
            "targets: tensor([1, 0, 0, 0], device='cuda:0')\n",
            "correct in this batch: 1\n",
            "n_correct = 3. n_samples = 8\n",
            "predictions: tensor([1, 1, 0, 0], device='cuda:0')\n",
            "targets: tensor([0, 1, 1, 0], device='cuda:0')\n",
            "correct in this batch: 2\n",
            "n_correct = 5. n_samples = 12\n",
            "Accuracy on validation set for epoch 11 = 41.7%\n",
            "Finished validation for epoch 11\n",
            "=============================================\n",
            "Training for epoch 12\n",
            "=============================================\n",
            "Epoch 12/20, step 7/14, loss = 0.0054\n",
            "Epoch 12/20, step 14/14, loss = 0.0036\n",
            "Finished training for epoch 12\n",
            "Validation for epoch 12\n",
            "=============================================\n",
            "predictions: tensor([0, 0, 1, 0], device='cuda:0')\n",
            "targets: tensor([0, 1, 1, 1], device='cuda:0')\n",
            "correct in this batch: 2\n",
            "n_correct = 2. n_samples = 4\n",
            "predictions: tensor([1, 0, 0, 0], device='cuda:0')\n",
            "targets: tensor([0, 0, 1, 1], device='cuda:0')\n",
            "correct in this batch: 1\n",
            "n_correct = 3. n_samples = 8\n",
            "predictions: tensor([0, 1, 1, 0], device='cuda:0')\n",
            "targets: tensor([0, 1, 0, 0], device='cuda:0')\n",
            "correct in this batch: 3\n",
            "n_correct = 6. n_samples = 12\n",
            "Accuracy on validation set for epoch 12 = 50.0%\n",
            "Finished validation for epoch 12\n",
            "=============================================\n",
            "Training for epoch 13\n",
            "=============================================\n",
            "Epoch 13/20, step 7/14, loss = 0.0062\n",
            "Epoch 13/20, step 14/14, loss = 0.0001\n",
            "Finished training for epoch 13\n",
            "Validation for epoch 13\n",
            "=============================================\n",
            "predictions: tensor([0, 1, 0, 0], device='cuda:0')\n",
            "targets: tensor([1, 1, 0, 0], device='cuda:0')\n",
            "correct in this batch: 3\n",
            "n_correct = 3. n_samples = 4\n",
            "predictions: tensor([0, 0, 1, 0], device='cuda:0')\n",
            "targets: tensor([1, 0, 1, 0], device='cuda:0')\n",
            "correct in this batch: 3\n",
            "n_correct = 6. n_samples = 8\n",
            "predictions: tensor([0, 1, 0, 1], device='cuda:0')\n",
            "targets: tensor([1, 0, 1, 0], device='cuda:0')\n",
            "correct in this batch: 0\n",
            "n_correct = 6. n_samples = 12\n",
            "Accuracy on validation set for epoch 13 = 50.0%\n",
            "Finished validation for epoch 13\n",
            "=============================================\n",
            "Training for epoch 14\n",
            "=============================================\n",
            "Epoch 14/20, step 7/14, loss = 0.0010\n",
            "Epoch 14/20, step 14/14, loss = 0.0003\n",
            "Finished training for epoch 14\n",
            "Validation for epoch 14\n",
            "=============================================\n",
            "predictions: tensor([1, 1, 0, 0], device='cuda:0')\n",
            "targets: tensor([0, 1, 1, 0], device='cuda:0')\n",
            "correct in this batch: 2\n",
            "n_correct = 2. n_samples = 4\n",
            "predictions: tensor([0, 0, 0, 1], device='cuda:0')\n",
            "targets: tensor([1, 0, 1, 1], device='cuda:0')\n",
            "correct in this batch: 2\n",
            "n_correct = 4. n_samples = 8\n",
            "predictions: tensor([0, 1, 0, 0], device='cuda:0')\n",
            "targets: tensor([1, 0, 0, 0], device='cuda:0')\n",
            "correct in this batch: 2\n",
            "n_correct = 6. n_samples = 12\n",
            "Accuracy on validation set for epoch 14 = 50.0%\n",
            "Finished validation for epoch 14\n",
            "=============================================\n",
            "Training for epoch 15\n",
            "=============================================\n",
            "Epoch 15/20, step 7/14, loss = 0.0000\n",
            "Epoch 15/20, step 14/14, loss = 0.0006\n",
            "Finished training for epoch 15\n",
            "Validation for epoch 15\n",
            "=============================================\n",
            "predictions: tensor([1, 0, 0, 1], device='cuda:0')\n",
            "targets: tensor([0, 1, 0, 0], device='cuda:0')\n",
            "correct in this batch: 1\n",
            "n_correct = 1. n_samples = 4\n",
            "predictions: tensor([0, 0, 0, 0], device='cuda:0')\n",
            "targets: tensor([0, 1, 0, 1], device='cuda:0')\n",
            "correct in this batch: 2\n",
            "n_correct = 3. n_samples = 8\n",
            "predictions: tensor([0, 1, 1, 1], device='cuda:0')\n",
            "targets: tensor([1, 1, 0, 1], device='cuda:0')\n",
            "correct in this batch: 2\n",
            "n_correct = 5. n_samples = 12\n",
            "Accuracy on validation set for epoch 15 = 41.7%\n",
            "Finished validation for epoch 15\n",
            "=============================================\n",
            "Training for epoch 16\n",
            "=============================================\n",
            "Epoch 16/20, step 7/14, loss = 0.0009\n",
            "Epoch 16/20, step 14/14, loss = 0.0002\n",
            "Finished training for epoch 16\n",
            "Validation for epoch 16\n",
            "=============================================\n",
            "predictions: tensor([0, 0, 0, 1], device='cuda:0')\n",
            "targets: tensor([1, 1, 0, 0], device='cuda:0')\n",
            "correct in this batch: 1\n",
            "n_correct = 1. n_samples = 4\n",
            "predictions: tensor([1, 0, 0, 1], device='cuda:0')\n",
            "targets: tensor([0, 1, 0, 1], device='cuda:0')\n",
            "correct in this batch: 2\n",
            "n_correct = 3. n_samples = 8\n",
            "predictions: tensor([1, 0, 0, 1], device='cuda:0')\n",
            "targets: tensor([0, 1, 0, 1], device='cuda:0')\n",
            "correct in this batch: 2\n",
            "n_correct = 5. n_samples = 12\n",
            "Accuracy on validation set for epoch 16 = 41.7%\n",
            "Finished validation for epoch 16\n",
            "=============================================\n",
            "Training for epoch 17\n",
            "=============================================\n",
            "Epoch 17/20, step 7/14, loss = 0.0006\n",
            "Epoch 17/20, step 14/14, loss = 0.0000\n",
            "Finished training for epoch 17\n",
            "Validation for epoch 17\n",
            "=============================================\n",
            "predictions: tensor([0, 0, 1, 0], device='cuda:0')\n",
            "targets: tensor([1, 0, 0, 1], device='cuda:0')\n",
            "correct in this batch: 1\n",
            "n_correct = 1. n_samples = 4\n",
            "predictions: tensor([1, 1, 0, 0], device='cuda:0')\n",
            "targets: tensor([1, 0, 1, 0], device='cuda:0')\n",
            "correct in this batch: 2\n",
            "n_correct = 3. n_samples = 8\n",
            "predictions: tensor([0, 1, 1, 0], device='cuda:0')\n",
            "targets: tensor([1, 0, 1, 0], device='cuda:0')\n",
            "correct in this batch: 2\n",
            "n_correct = 5. n_samples = 12\n",
            "Accuracy on validation set for epoch 17 = 41.7%\n",
            "Finished validation for epoch 17\n",
            "=============================================\n",
            "Training for epoch 18\n",
            "=============================================\n",
            "Epoch 18/20, step 7/14, loss = 0.0001\n",
            "Epoch 18/20, step 14/14, loss = 0.0002\n",
            "Finished training for epoch 18\n",
            "Validation for epoch 18\n",
            "=============================================\n",
            "predictions: tensor([0, 0, 0, 1], device='cuda:0')\n",
            "targets: tensor([1, 1, 0, 1], device='cuda:0')\n",
            "correct in this batch: 2\n",
            "n_correct = 2. n_samples = 4\n",
            "predictions: tensor([1, 1, 0, 0], device='cuda:0')\n",
            "targets: tensor([0, 1, 1, 0], device='cuda:0')\n",
            "correct in this batch: 2\n",
            "n_correct = 4. n_samples = 8\n",
            "predictions: tensor([1, 0, 1, 0], device='cuda:0')\n",
            "targets: tensor([0, 1, 0, 0], device='cuda:0')\n",
            "correct in this batch: 1\n",
            "n_correct = 5. n_samples = 12\n",
            "Accuracy on validation set for epoch 18 = 41.7%\n",
            "Finished validation for epoch 18\n",
            "=============================================\n",
            "Training for epoch 19\n",
            "=============================================\n",
            "Epoch 19/20, step 7/14, loss = 0.0000\n",
            "Epoch 19/20, step 14/14, loss = 0.0001\n",
            "Finished training for epoch 19\n",
            "Validation for epoch 19\n",
            "=============================================\n",
            "predictions: tensor([1, 1, 1, 1], device='cuda:0')\n",
            "targets: tensor([1, 1, 0, 0], device='cuda:0')\n",
            "correct in this batch: 2\n",
            "n_correct = 2. n_samples = 4\n",
            "predictions: tensor([0, 0, 1, 0], device='cuda:0')\n",
            "targets: tensor([1, 0, 0, 1], device='cuda:0')\n",
            "correct in this batch: 1\n",
            "n_correct = 3. n_samples = 8\n",
            "predictions: tensor([0, 0, 0, 0], device='cuda:0')\n",
            "targets: tensor([0, 1, 1, 0], device='cuda:0')\n",
            "correct in this batch: 2\n",
            "n_correct = 5. n_samples = 12\n",
            "Accuracy on validation set for epoch 19 = 41.7%\n",
            "Finished validation for epoch 19\n",
            "=============================================\n",
            "Training for epoch 20\n",
            "=============================================\n",
            "Epoch 20/20, step 7/14, loss = 0.0000\n",
            "Epoch 20/20, step 14/14, loss = 0.0001\n",
            "Finished training for epoch 20\n",
            "Validation for epoch 20\n",
            "=============================================\n",
            "predictions: tensor([0, 0, 0, 0], device='cuda:0')\n",
            "targets: tensor([1, 0, 0, 1], device='cuda:0')\n",
            "correct in this batch: 2\n",
            "n_correct = 2. n_samples = 4\n",
            "predictions: tensor([0, 1, 0, 1], device='cuda:0')\n",
            "targets: tensor([1, 0, 1, 0], device='cuda:0')\n",
            "correct in this batch: 0\n",
            "n_correct = 2. n_samples = 8\n",
            "predictions: tensor([1, 0, 1, 1], device='cuda:0')\n",
            "targets: tensor([0, 0, 1, 1], device='cuda:0')\n",
            "correct in this batch: 3\n",
            "n_correct = 5. n_samples = 12\n",
            "Accuracy on validation set for epoch 20 = 41.7%\n",
            "Finished validation for epoch 20\n",
            "=============================================\n",
            "FINISHED TRAINING\n",
            "predictions: tensor([1, 1, 0, 0], device='cuda:0')\n",
            "targets: tensor([1, 1, 0, 0], device='cuda:0')\n",
            "n_correct = 4. n_samples = 4\n",
            "predictions: tensor([1, 0, 0, 1], device='cuda:0')\n",
            "targets: tensor([1, 1, 0, 1], device='cuda:0')\n",
            "n_correct = 7. n_samples = 8\n",
            "predictions: tensor([1, 0, 0, 0], device='cuda:0')\n",
            "targets: tensor([0, 0, 1, 0], device='cuda:0')\n",
            "n_correct = 9. n_samples = 12\n",
            "Accuracy on training set = 75.0%\n"
          ]
        }
      ],
      "source": [
        "#training_loop\n",
        "num_epochs = 20\n",
        "n_total_steps = len(train_dataloader)\n",
        "#print(n_total_steps)\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "  print(f'Training for epoch {epoch+1}')\n",
        "  print('=============================================')\n",
        "  for i, (images, labels) in enumerate(train_dataloader):\n",
        "    images = reshape(images, (images.shape[0],1 ,264,264,264))\n",
        "    images = images.float()\n",
        "    #print(labels)\n",
        "    hot_labels = torch.empty((images.shape[0], 2))\n",
        "    #print(new_labels.shape)\n",
        "    for index in range(len(labels)):\n",
        "          if labels[index] == 0 :\n",
        "            hot_labels[index,0] = 1\n",
        "            hot_labels[index,1] = 0\n",
        "          elif labels[index] == 1 :\n",
        "            hot_labels[index,0] = 0\n",
        "            hot_labels[index,1] = 1\n",
        "    images = images.to(device)\n",
        "    hot_labels = hot_labels.to(device)\n",
        "\n",
        "    #forward pass\n",
        "    outputs = model(images)\n",
        "    #print(outputs)\n",
        "    loss = criterion(outputs, hot_labels)\n",
        "\n",
        "    #backwards pass\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if (i+1)%7 == 0:\n",
        "      print(f'Epoch {epoch+1}/{num_epochs}, step {i+1}/{n_total_steps}, loss = {loss.item():.4f}')\n",
        "  print(f'Finished training for epoch {epoch+1}')\n",
        "  print(f'Validation for epoch {epoch+1}')\n",
        "  print('=============================================')\n",
        "  with torch.no_grad():\n",
        "    n_correct = 0\n",
        "    n_samples = 0\n",
        "    for images, labels in validation_dataloader :\n",
        "      images = images = reshape(images, (images.shape[0],1 ,264,264,264))\n",
        "      images = images.float()\n",
        "      hot_labels = torch.empty((images.shape[0], 2))\n",
        "      #print(new_labels.shape)\n",
        "      for index in range(len(labels)):\n",
        "          if labels[index] == 0 :\n",
        "            hot_labels[index,0] = 1\n",
        "            hot_labels[index,1] = 0\n",
        "          elif labels[index] == 1 :\n",
        "            hot_labels[index,0] = 0\n",
        "            hot_labels[index,1] = 1\n",
        "      images = images.to(device)\n",
        "      hot_labels = hot_labels.to(device)\n",
        "      outputs = model(images)\n",
        "      # max returns (value, index) \n",
        "      _,predictions = torch.max(outputs, 1)\n",
        "      _,targets = torch.max(hot_labels, 1)\n",
        "      print(f'predictions: {predictions}')\n",
        "      print(f'targets: {targets}')\n",
        "      print(f'correct in this batch: {(predictions == targets).sum().item()}')\n",
        "      n_samples += labels.shape[0]\n",
        "      n_correct += (predictions == targets).sum().item()\n",
        "      print(f'n_correct = {n_correct}. n_samples = {n_samples}')\n",
        "\n",
        "    acc = (100*n_correct)/n_samples\n",
        "    print(f'Accuracy on validation set for epoch {epoch+1} = {acc:.1f}%')\n",
        "\n",
        "    print(f'Finished validation for epoch {epoch+1}')\n",
        "    print('=============================================')\n",
        "\n",
        "print('FINISHED TRAINING')\n",
        "\n",
        "#testing\n",
        "with torch.no_grad():\n",
        "    n_correct = 0\n",
        "    n_samples = 0\n",
        "    for images, labels in test_dataloader :\n",
        "      images = images = reshape(images, (images.shape[0],1 ,264,264,264))\n",
        "      images = images.float()\n",
        "      hot_labels = torch.empty((images.shape[0], 2))\n",
        "      #print(new_labels.shape)\n",
        "      for index in range(len(labels)):\n",
        "          if labels[index] == 0 :\n",
        "            hot_labels[index,0] = 1\n",
        "            hot_labels[index,1] = 0\n",
        "          elif labels[index] == 1 :\n",
        "            hot_labels[index,0] = 0\n",
        "            hot_labels[index,1] = 1\n",
        "      images = images.to(device)\n",
        "      hot_labels = hot_labels.to(device)\n",
        "      outputs = model(images)\n",
        "      # max returns (value, index) \n",
        "      _,predictions = torch.max(outputs, 1)\n",
        "      _,targets = torch.max(hot_labels,1)\n",
        "      print(f'predictions: {predictions}')\n",
        "      print(f'targets: {targets}')\n",
        "      n_samples += hot_labels.shape[0]\n",
        "      n_correct += (predictions == targets).sum().item()\n",
        "      print(f'n_correct = {n_correct}. n_samples = {n_samples}')\n",
        "    \n",
        "    acc = (100*n_correct)/n_samples\n",
        "    print(f'Accuracy on training set = {acc:.1f}%')\n",
        "\n",
        "\n",
        "# time renewal\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "CNN4.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNPSgReRo+lD0kdkojqhnZx",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}