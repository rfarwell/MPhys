{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CNN_Clean.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNub0V3DC0H98OHNHvHgzCc",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rfarwell/MPhys/blob/main/CNN_Clean.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "j1-myAHL16TH",
        "outputId": "bd22e6fa-c3e2-4447-b3b0-3df52d353d44"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (1.10.0+cu111)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.7/dist-packages (0.11.1+cu111)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch) (3.10.0.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchvision) (1.19.5)\n",
            "Requirement already satisfied: pillow!=8.3.0,>=5.3.0 in /usr/local/lib/python3.7/dist-packages (from torchvision) (7.1.2)\n",
            "Requirement already satisfied: opencv-contrib-python in /usr/local/lib/python3.7/dist-packages (4.1.2.30)\n",
            "Requirement already satisfied: numpy>=1.14.5 in /usr/local/lib/python3.7/dist-packages (from opencv-contrib-python) (1.19.5)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (1.0.2)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn) (1.4.1)\n",
            "Requirement already satisfied: numpy>=1.14.6 in /usr/local/lib/python3.7/dist-packages (from scikit-learn) (1.19.5)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn) (3.1.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn) (1.1.0)\n",
            "Requirement already satisfied: SimpleITK in /usr/local/lib/python3.7/dist-packages (2.1.1)\n",
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n",
            "Using cuda device\n",
            "/content/gdrive/MyDrive/Data/NSCLC-Radiomics-Clinical-Data.csv\n",
            "metadata_file path: /content/gdrive/MyDrive/Data/NSCLC-Radiomics-Clinical-Data.csv\n",
            "Length of metadata array is 400\n",
            "Number of patients dead after 547.5 days: 200\n",
            "Number of patients alive counter after 547.5 days: 200\n",
            "Number of right-censored data when using a check day of 547.5 days: 0\n",
            "The alive and dead arrays have been sorted (randomly) so that they are both of length 200, 200\n",
            "After separation into training, validation and testing arrays the number of unused data is 0. If not then something has gone wrong.\n",
            "Length of shuffled outcomes_train: 280\n",
            "Length of shuffled outcomes_validate: 60\n",
            "Length of shuffled outcomes_test: 60\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv3d-1     [4, 32, 132, 132, 132]             288\n",
            "         MaxPool3d-2        [4, 32, 66, 66, 66]               0\n",
            "            Conv3d-3        [4, 64, 33, 33, 33]          16,448\n",
            "         MaxPool3d-4        [4, 64, 16, 16, 16]               0\n",
            "            Conv3d-5          [4, 128, 8, 8, 8]          65,664\n",
            "         MaxPool3d-6          [4, 128, 4, 4, 4]               0\n",
            "            Conv3d-7           [4, 64, 4, 4, 4]           8,256\n",
            "            Conv3d-8           [4, 16, 4, 4, 4]           1,040\n",
            "            Conv3d-9            [4, 2, 4, 4, 4]              34\n",
            "        AvgPool3d-10            [4, 2, 1, 1, 1]               0\n",
            "================================================================\n",
            "Total params: 91,730\n",
            "Trainable params: 91,730\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 280.76\n",
            "Forward/backward pass size (MB): 2607.42\n",
            "Params size (MB): 0.35\n",
            "Estimated Total Size (MB): 2888.53\n",
            "----------------------------------------------------------------\n",
            "Training for epoch 1\n",
            "=============================\n",
            "Epoch 1/8, step 1/70, loss = 0.7274\n",
            "Epoch 1/8, step 2/70, loss = 0.6638\n",
            "Epoch 1/8, step 3/70, loss = 0.6951\n",
            "Epoch 1/8, step 4/70, loss = 0.7218\n",
            "Epoch 1/8, step 5/70, loss = 0.6686\n",
            "Epoch 1/8, step 6/70, loss = 0.6955\n",
            "Epoch 1/8, step 7/70, loss = 0.6957\n",
            "Epoch 1/8, step 8/70, loss = 0.6674\n",
            "Epoch 1/8, step 9/70, loss = 0.6659\n",
            "Epoch 1/8, step 10/70, loss = 0.7577\n",
            "Epoch 1/8, step 11/70, loss = 0.6951\n",
            "Epoch 1/8, step 12/70, loss = 0.7252\n",
            "Epoch 1/8, step 13/70, loss = 0.7244\n",
            "Epoch 1/8, step 14/70, loss = 0.6949\n",
            "Epoch 1/8, step 15/70, loss = 0.7471\n",
            "Epoch 1/8, step 16/70, loss = 0.6931\n",
            "Epoch 1/8, step 17/70, loss = 0.7136\n",
            "Epoch 1/8, step 18/70, loss = 0.6785\n",
            "Epoch 1/8, step 19/70, loss = 0.6787\n",
            "Epoch 1/8, step 20/70, loss = 0.6931\n",
            "Epoch 1/8, step 21/70, loss = 0.7090\n",
            "Epoch 1/8, step 22/70, loss = 0.6940\n",
            "Epoch 1/8, step 23/70, loss = 0.6923\n",
            "Epoch 1/8, step 24/70, loss = 0.7057\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-46f910512b6d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    572\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    573\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 574\u001b[0;31m     \u001b[0mavg_train_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mavg_train_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_loop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    575\u001b[0m     \u001b[0mavg_valid_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mavg_valid_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_loop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    576\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-5-46f910512b6d>\u001b[0m in \u001b[0;36mtraining_loop\u001b[0;34m()\u001b[0m\n\u001b[1;32m    235\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 237\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    238\u001b[0m         \u001b[0mimages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m264\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m264\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m264\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    239\u001b[0m         \u001b[0mimages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    519\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    520\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 521\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    522\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    559\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    560\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 561\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    562\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    563\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-5-46f910512b6d>\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m    401\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    402\u001b[0m     \u001b[0mimg_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimg_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimg_labels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"-GTV-1.nii\"\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 403\u001b[0;31m     \u001b[0mimage_sitk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msitk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mReadImage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    404\u001b[0m     \u001b[0;31m# ID = self.img_labels[idx][0]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    405\u001b[0m     \u001b[0;31m# print(f'ID: {ID}')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/SimpleITK/extra.py\u001b[0m in \u001b[0;36mReadImage\u001b[0;34m(fileName, outputPixelType, imageIO)\u001b[0m\n\u001b[1;32m    344\u001b[0m     \u001b[0mreader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSetImageIO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimageIO\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    345\u001b[0m     \u001b[0mreader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSetOutputPixelType\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputPixelType\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 346\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mreader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    347\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    348\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/SimpleITK/SimpleITK.py\u001b[0m in \u001b[0;36mExecute\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   8013\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   8014\u001b[0m         \"\"\"\n\u001b[0;32m-> 8015\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_SimpleITK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mImageFileReader_Execute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   8016\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   8017\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mReadImageInformation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "\"\"\"\n",
        "This code trains, validates and tests a custom binary classfiying CNN.\n",
        "\n",
        "The inputs to the network are 264 x 264 x 264 textured masks of NSCLC pre-treatment CT scans.\n",
        "\n",
        "Rory Farwell and Patrick Hastings 08/02/2022\n",
        "\n",
        "\"\"\"\n",
        "#====================================================================\n",
        "#======================= IMPORTING FUNCTIONS ========================\n",
        "#====================================================================\n",
        "\n",
        "# Un hash below if on Google Colab\n",
        "!pip install torch torchvision\n",
        "!pip install opencv-contrib-python\n",
        "!pip install scikit-learn\n",
        "!pip install SimpleITK\n",
        "\n",
        "import numpy as np\n",
        "import random\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import SimpleITK as sitk\n",
        "import torch\n",
        "\n",
        "from mpl_toolkits.mplot3d import Axes3D\n",
        "from torch.nn import Module\n",
        "from torch.nn import Conv3d\n",
        "from torch.nn import Linear\n",
        "from torch.nn import MaxPool2d\n",
        "from torch.nn import ReLU\n",
        "from torch.nn import LogSoftmax\n",
        "from torch import flatten\n",
        "from torch import nn\n",
        "from torch import reshape\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import transforms\n",
        "from torchvision import datasets\n",
        "from torchvision.io import read_image\n",
        "from torch.optim import Adam\n",
        "import torchvision.models as models\n",
        "from torch.autograd import Variable\n",
        "from torchsummary import summary\n",
        "\n",
        "#====================================================================\n",
        "#=================== COLAB SPECIFIC CODE ============================\n",
        "#====================================================================\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "\n",
        "#====================================================================\n",
        "#=================== SELECT DEVICE ==================================\n",
        "#====================================================================\n",
        "\n",
        "# Connect to GPU is available\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "print(f'Using {device} device')\n",
        "# /content/gdrive/MyDrive/MPhys/Data/COLAB-Clinical-Data.csv\n",
        "# Specify project folder location\n",
        "project_folder = \"/content/gdrive/MyDrive/Data\"\n",
        "clinical_data_filename = \"NSCLC-Radiomics-Clinical-Data.csv\"\n",
        "print(os.path.join(project_folder, clinical_data_filename))\n",
        "\n",
        "#====================================================================\n",
        "#=================== DEFINING FUNCTIONS =============================\n",
        "#====================================================================\n",
        "\n",
        "def equalise_array_lengths(array_1, array_2) :\n",
        "  \"\"\"\n",
        "  This functions takes in the arguments of two lists and makes sure they are returned as the same length.\n",
        "\n",
        "  Rory Farwell 02/12/2021\n",
        "  \"\"\"\n",
        "  # output_array = []\n",
        "\n",
        "  if len(array_1) > len(array_2) :\n",
        "    array_1 = array_1[:len(array_2)]\n",
        "  elif len(array_1) < len(array_2) :\n",
        "    array_2 = array_2[:len(array_1)]\n",
        "\n",
        "  # array_1 = array_1[:20]\n",
        "  # array_2 = array_2[:20]\n",
        "\n",
        "  return (array_1, array_2)\n",
        "\n",
        "def remove_same_elements(small_array, long_array) :\n",
        "  \"\"\"\n",
        "  For use in the context, all the elements in small_array come from long_array.\n",
        "  This function will remove all of the elements used in small_array from_long_array.  \n",
        "  \"\"\"\n",
        "  for element in small_array :\n",
        "    long_array.remove(element)\n",
        "  return long_array\n",
        "\n",
        "def create_subgroup(input_array, original_array_length, desired_percentage) :\n",
        "  \"\"\"\n",
        "  This function outputs a subgroup array (e.g. training array) using a specified output array name,\n",
        "  input array and percentage length\n",
        "  \"\"\"\n",
        "  desired_length = int(original_array_length * desired_percentage)\n",
        "  output_array = random.sample(input_array, desired_length)\n",
        "  return output_array\n",
        "\n",
        "def open_metadata() :\n",
        "    \"\"\"\n",
        "    Opens the metadata file using the globall defined variables 'project_folder' and 'clinical_data_filename'.\n",
        "\n",
        "    Returns patient_IDs which will be used for checking the data is shuffled\n",
        "    Returns time_markers which will be used for checking patient status at a specified timepoint\n",
        "    Returns dead_statuses.\n",
        "\n",
        "    Rory Farwell and Patrick Hastings 08/02/2022\n",
        "    \"\"\"\n",
        "    metadata_file = os.path.join(project_folder, clinical_data_filename)\n",
        "    print(f'metadata_file path: {metadata_file}')\n",
        "    metadata = np.genfromtxt(metadata_file, comments = '%', dtype=\"str\", delimiter=\",\")\n",
        "    print(f\"Length of metadata array is {len(metadata)}\")\n",
        "\n",
        "    # Retrieve data from metadata file\n",
        "    patient_IDs = metadata[:,0] # selecting patient IDs from the csv file\n",
        "    time_markers = metadata[:,8] # selecting the day of the last patient review from the csv file\n",
        "    dead_statuses = metadata[:,9] # selecting the dead status on the last review day\n",
        "\n",
        "    time_markers = time_markers.astype(np.float32) # converting to float\n",
        "    dead_statuses = dead_statuses.astype(np.float32) # converting to float\n",
        "\n",
        "    return patient_IDs, time_markers, dead_statuses\n",
        "\n",
        "def patient_status_on_check_day(check_day) :\n",
        "    \"\"\"\n",
        "    Changes patient status according to patient status on the check day.\n",
        "    There are 4 possibilities here:\n",
        "    1. Dead: timepoint < check_day -> Dead on check day [1 -> 1]\n",
        "    2. Dead: timepoint > check_day -> Alive on check day [1 -> 0]\n",
        "    3. Alive: timepoint > check_day -> Alive on check day [0 -> 0]\n",
        "    4. Alive: timepoint < check_day -> no info on current status -> right-censored data\n",
        "\n",
        "    Rory Farwell and Patrick Hastings 08/02/2022\n",
        "    \"\"\"\n",
        "\n",
        "    dead_counter = 0\n",
        "    alive_counter = 0\n",
        "    no_info_counter = 0\n",
        "    dead_patient_array = []\n",
        "    alive_patient_array = []\n",
        "\n",
        "    for i in range(len(dead_statuses)) :\n",
        "        temp_patient_ID = patient_IDs[i]\n",
        "        temp_dead_status = dead_statuses[i]\n",
        "        temp_time_marker = time_markers[i]\n",
        "        if temp_dead_status == 1 : #if the patient is dead\n",
        "            if temp_time_marker < check_day :# situation 1\n",
        "                dead_patient_array.append([temp_patient_ID, 1])\n",
        "                dead_counter += 1\n",
        "                continue\n",
        "            elif temp_time_marker > check_day : # situation 2\n",
        "                alive_patient_array.append([temp_patient_ID, 0])\n",
        "                alive_counter += 1\n",
        "                continue\n",
        "        elif temp_dead_status == 0 : #if the patient is alive\n",
        "            if temp_time_marker < check_day : # situation 4\n",
        "                no_info_counter += 1\n",
        "                continue\n",
        "            elif temp_time_marker > check_day :\n",
        "                alive_patient_array.append([temp_patient_ID, 0])\n",
        "                alive_counter += 1\n",
        "                continue\n",
        "\n",
        "    # Printing the results of this loop (the number of dead and alive patients at the check day)\n",
        "    print(f\"Number of patients dead after {check_day} days: {dead_counter}\")\n",
        "    print(f\"Number of patients alive counter after {check_day} days: {alive_counter}\")\n",
        "    print(f\"Number of right-censored data when using a check day of {check_day} days: {no_info_counter}\")\n",
        "\n",
        "    return dead_patient_array, alive_patient_array\n",
        "\n",
        "def equalise_arrays(array_1, array_2) :\n",
        "    \"\"\"\n",
        "    Equalise the length arrays 1 and 2 to the length of the shortest of the two.\n",
        "\n",
        "    Rory Farwell and Patrick Hastings 08/02/2022\n",
        "    \"\"\"\n",
        "    new_array_1 = equalise_array_lengths(array_1, array_2)[0]\n",
        "    new_array_2 = equalise_array_lengths(array_1, array_2)[1]\n",
        "    print(f\"The alive and dead arrays have been sorted (randomly) so that they are both of length {len(new_array_1)}, {len(new_array_2)}\")\n",
        "\n",
        "    return new_array_1, new_array_2\n",
        "\n",
        "def create_final_datasets() :\n",
        "    \"\"\"\n",
        "    Combines the dead and alive arrays of each training, validation and testing data sets to produce the final lists.\n",
        "    And shuffles them.\n",
        "\n",
        "    Rory Farwell and Patrick Hastings 08/02/2022\n",
        "    \"\"\"\n",
        "    outcomes_train = train_patients_dead + train_patients_alive\n",
        "    outcomes_test = test_patients_dead + test_patients_alive\n",
        "    outcomes_validate = validate_patients_dead + validate_patients_alive\n",
        "    \n",
        "    random.shuffle(outcomes_train)\n",
        "    random.shuffle(outcomes_test)\n",
        "    random.shuffle(outcomes_validate)\n",
        "\n",
        "    print(f'Length of shuffled outcomes_train: {len(outcomes_train)}') \n",
        "    print(f'Length of shuffled outcomes_validate: {len(outcomes_validate)}')\n",
        "    print(f'Length of shuffled outcomes_test: {len(outcomes_test)}')\n",
        "\n",
        "    return outcomes_train, outcomes_validate, outcomes_test\n",
        "\n",
        "def convert_to_one_hot_labels(images, labels) :\n",
        "    \"\"\"\n",
        "    This function converts the labels to one-hot labels so that they will work with the BCEwithLogitsLoss\n",
        "    \"\"\"\n",
        "    hot_labels = torch.empty((images.shape[0], 2))\n",
        "    \n",
        "    for index in range(len(labels)) :\n",
        "        if labels[index] == 0 :\n",
        "            hot_labels[index,0] = 1\n",
        "            hot_labels[index,1] = 0\n",
        "        elif labels[index] == 1 :\n",
        "            hot_labels[index, 0] = 0\n",
        "            hot_labels[index, 1] = 1\n",
        "    \n",
        "    return hot_labels\n",
        "\n",
        "def training_loop():\n",
        "    epoch_train_loss = 0 # will be used for plotting testing vs validation loss curves\n",
        "    n_training_samples = 0\n",
        "    print(f'Training for epoch {epoch+1}')\n",
        "    print(\"=============================\")\n",
        "\n",
        "    model.train()\n",
        "\n",
        "    for i, (images, labels) in enumerate(train_dataloader):\n",
        "        images = reshape(images, (images.shape[0], 1, 264, 264, 264))\n",
        "        images = images.float()\n",
        "\n",
        "        hot_labels = convert_to_one_hot_labels(images, labels)\n",
        "        \n",
        "        images = images.to(device)\n",
        "        hot_labels = hot_labels.to(device)\n",
        "\n",
        "        # print(hot_labels.size())\n",
        "        # print(hot_labels)\n",
        "\n",
        "   \n",
        "\n",
        "        #forward pass\n",
        "        outputs = model(images)\n",
        "        # print (outputs)\n",
        "        loss = criterion(outputs, hot_labels)\n",
        "\n",
        "        #backwards pass\n",
        "        optimizer.zero_grad() #clears gradients before performing backpropagation\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # Add the number of images in this batch to n_training_samples which will\n",
        "        # be used when calculating the average loss per image in the training set\n",
        "        n_training_samples += labels.shape[0]\n",
        "\n",
        "        # Updating the total training loss of this epoch\n",
        "        all_training_losses.append(loss.item())\n",
        "        epoch_train_loss += loss.item()\n",
        "\n",
        "        if (i+1)%1 == 0 :\n",
        "            print(f'Epoch {epoch+1}/{num_epochs}, step {i+1}/{n_total_steps}, loss = {loss.item():.4f}')\n",
        "\n",
        "    # Append the train_loss list with the total training loss for this epoch\n",
        "    train_loss.append(epoch_train_loss)\n",
        "\n",
        "    #Append the avg_train_loss list with the average training loss of this epoch\n",
        "    avg_train_loss = epoch_train_loss/n_training_samples\n",
        "    print(f\"Average training loss list: {avg_train_loss}\")\n",
        "\n",
        "    print(f\"Training loss array at end of epoch {epoch + 1}: {train_loss}. Total number of images used = {n_training_samples}.\")\n",
        "    print(f\"Finished training for epoch {epoch + 1}\")\n",
        "\n",
        "    return avg_train_loss\n",
        "\n",
        "def validation_loop() :\n",
        "    print(f'Validation for epoch {epoch + 1}')\n",
        "    print('=================================')\n",
        "\n",
        "    model.eval()\n",
        "\n",
        "    with torch.no_grad(): # ensuring gradients are not calculated during the validation loop\n",
        "        valid_epoch_loss = 0\n",
        "        n_valid_correct = 0\n",
        "        n_valid_samples = 0\n",
        "        for images, labels in validation_dataloader :\n",
        "            images = reshape(images, (images.shape[0],1 ,264,264,264))\n",
        "            images = images.float()\n",
        "            hot_labels = convert_to_one_hot_labels(images, labels)\n",
        "\n",
        "            images = images.to(device)\n",
        "            hot_labels = hot_labels.to(device)\n",
        "            outputs = model(images)\n",
        "\n",
        "            # calculate loss of validation set\n",
        "            loss = criterion(outputs, hot_labels)\n",
        "            valid_epoch_loss += loss.item()\n",
        "\n",
        "            # max returns (value, index) \n",
        "            _,predictions = torch.max(outputs, 1)\n",
        "            _,targets = torch.max(hot_labels, 1)\n",
        "            #print(f'predictions: {predictions}')\n",
        "            #print(f'targets: {targets}')\n",
        "            #print(f'correct in this batch: {(predictions == targets).sum().item()}')\n",
        "            n_valid_samples += labels.shape[0]\n",
        "            n_valid_correct += (predictions == targets).sum().item()\n",
        "            #print(f'n_correct = {n_correct}. n_samples = {n_samples}')\n",
        "        avg_valid_loss = valid_epoch_loss/n_valid_samples\n",
        "        #valid_loss.append(valid_epoch_loss)\n",
        "        acc = (100*n_valid_correct)/n_valid_samples\n",
        "        print(f'Accuracy on validation set for epoch {epoch+1} = {acc:.1f}%')\n",
        "        print(f'Loss on validation set = {valid_epoch_loss}')\n",
        "\n",
        "        print(f'Finished validation for epoch {epoch+1}')\n",
        "        print('=============================================')\n",
        "    return avg_valid_loss\n",
        "\n",
        "def testing_loop():\n",
        "  print(\"---- Currently testing the network on unseen data ----\")\n",
        "  model.eval()\n",
        "\n",
        "  with torch.no_grad():\n",
        "    n_correct = 0\n",
        "    n_samples = 0\n",
        "    counter = 0\n",
        "    for images, labels in test_dataloader :\n",
        "      # counter+=1\n",
        "      # print(counter)\n",
        "      images = images = reshape(images, (images.shape[0],1 ,264,264,264))\n",
        "      images = images.float()\n",
        "      hot_labels = convert_to_one_hot_labels(images, labels)\n",
        "\n",
        "      images = images.to(device)\n",
        "      hot_labels = hot_labels.to(device)\n",
        "      outputs = model(images)\n",
        "      # max returns (value, index) \n",
        "      _,predictions = torch.max(outputs, 1)\n",
        "      _,targets = torch.max(hot_labels,1)\n",
        "      #print(f'predictions: {predictions}')\n",
        "      #print(f'targets: {targets}')\n",
        "      n_samples += hot_labels.shape[0]\n",
        "      n_correct += (predictions == targets).sum().item()\n",
        "      #print(f'n_correct = {n_correct}. n_samples = {n_samples}')\n",
        "    \n",
        "    acc = (100*n_correct)/n_samples\n",
        "\n",
        "    return acc\n",
        "\n",
        "def plot_loss_curves() :\n",
        "  new_avg_train_loss = avg_train_loss\n",
        "  new_avg_valid_loss = avg_valid_loss\n",
        "\n",
        "  epochs = np.array(range(num_epochs)) + 1\n",
        "  fig = plt.figure()\n",
        "  plt.xticks(fontsize=20)\n",
        "  plt.yticks(fontsize=20)\n",
        "  fig.set_size_inches(20, 10)\n",
        "  plt.plot(epochs, new_avg_train_loss, label = 'Average training loss',linewidth=7.0)\n",
        "  plt.plot(epochs, new_avg_valid_loss, label = 'Average validation loss',linewidth=7.0)\n",
        "  plt.legend(loc='best', prop={'size': 20})\n",
        "  plt.ylabel('Average Loss', fontsize = 20)\n",
        "  plt.xlabel('Epoch Number', fontsize = 20)\n",
        "  plt.show()\n",
        "  return\n",
        "#====================================================================\n",
        "#=================  CLASS DEFINITIONS ===============================\n",
        "#====================================================================\n",
        "\n",
        "# Normalize class added 12/12/2021\n",
        "class Normalize():\n",
        "  def __init__(self):\n",
        "    pass\n",
        "\n",
        "  def __call__(self,vol):\n",
        "    vol =((vol-(vol.mean()))/vol.std()) + 1\n",
        "    return vol\n",
        "\n",
        "transform = transforms.Compose(\n",
        "    [transforms.ToTensor(), Normalize() ] #added 13/12/2021 to normalize the inputs. THIS NORMALIZES to mean = 0 and std = 1\n",
        ")\n",
        "\n",
        "\n",
        "class ImageDataset(Dataset) :\n",
        "  def __init__(self, annotations, img_dir, transform = transform, target_transform = None) :\n",
        "    self.img_labels = annotations\n",
        "    self.img_dir = img_dir\n",
        "    self.transform = transform\n",
        "    self.target_transform = target_transform\n",
        "\n",
        "  def __len__(self) :\n",
        "    return len(self.img_labels)\n",
        "\n",
        "  def __getitem__(self,idx) :\n",
        "    img_path = os.path.join(self.img_dir, self.img_labels[idx][0] + \"-GTV-1.nii\" )\n",
        "    image_sitk = sitk.ReadImage(img_path)\n",
        "    # ID = self.img_labels[idx][0]\n",
        "    # print(f'ID: {ID}')\n",
        "    image = sitk.GetArrayFromImage(image_sitk)\n",
        "    label = self.img_labels[idx][1]\n",
        "    if self.transform :\n",
        "      image = self.transform(image)\n",
        "    if self.target_transform :\n",
        "      label = self.target_transform(label)\n",
        "    return image,label\n",
        "\n",
        "class CNN(nn.Module):   \n",
        "    def __init__(self):\n",
        "        super(CNN, self).__init__()\n",
        "        # self.conv1 = nn.Conv3d(1,4,2,2)\n",
        "        # self.pool = nn.MaxPool3d(2,2)\n",
        "        # self.avg_pool = nn.AvgPool3d(2)\n",
        "        # self.conv2 = nn.Conv3d(4,16,2,2)\n",
        "        # self.conv3 = nn.Conv3d(16,64,2,2)\n",
        "        # self.conv4 = nn.Conv3d(64,256,2,2)\n",
        "        # self.dropout = nn.Dropout(0.25)\n",
        "        # self.fc1 = nn.Linear(256,64)\n",
        "        # self.fc2 = nn.Linear(64,16)\n",
        "        # self.fc3 = nn.Linear(16,2)\n",
        "\n",
        "    # def __init__(self):\n",
        "    #     super(CNN, self).__init__()\n",
        "        # self.conv1 = nn.Conv3d(1,16,2,2)\n",
        "        # self.pool = nn.MaxPool3d(2,2)\n",
        "        # self.avg_pool = nn.AvgPool3d(2)\n",
        "        # self.conv2 = nn.Conv3d(16,16,2,2)\n",
        "        # self.conv3 = nn.Conv3d(16,16,2,2)\n",
        "        # self.conv4 = nn.Conv3d(16,8,2,2)\n",
        "        # self.dropout = nn.Dropout(0.25)\n",
        "        # self.fc1 = nn.Linear(16,64)\n",
        "        # self.fc2 = nn.Linear(64,16)\n",
        "        # self.fc3 = nn.Linear(16,2)\n",
        "\n",
        "    def __init__(self):\n",
        "      super(CNN, self).__init__()\n",
        "      self.conv1 = nn.Conv3d(1,32,2,2)\n",
        "      self.pool = nn.MaxPool3d(2,2)\n",
        "      self.avg_pool = nn.AvgPool3d(4)\n",
        "      self.conv2 = nn.Conv3d(32,64,2,2)\n",
        "      self.conv3 = nn.Conv3d(64,128,2,2)\n",
        "      self.conv4 = nn.Conv3d(128,64,1,1)\n",
        "      self.conv5 = nn.Conv3d(64,16,1,1)\n",
        "      self.conv6 = nn.Conv3d(16,2,1,1)\n",
        "\n",
        "    # Defining the forward pass    (original)\n",
        "    # def forward(self, x):\n",
        "    #     print(f'Input to the network: {x}')\n",
        "    #     x = self.pool(F.leaky_relu(self.conv1(x)))\n",
        "    #     x = self.pool(F.leaky_relu(self.conv2(x)))\n",
        "    #     x = self.pool(F.leaky_relu(self.conv3(x)))\n",
        "    #     x = self.avg_pool(F.leaky_relu(self.conv4(x)))\n",
        "    #     print(f'After average pooling layer: {x}')\n",
        "    #     x = x.view(-1, 16)\n",
        "    #     print(f'After flattening: {x}')\n",
        "    #     x = self.dropout(x)\n",
        "    #     x = F.leaky_relu(self.fc1(x))\n",
        "    #     x = self.dropout(x)\n",
        "    #     x = F.leaky_relu(self.fc2(x))\n",
        "        \n",
        "    #     x = self.dropout(x)\n",
        "        \n",
        "    #     x = self.fc3(x)\n",
        "    #     print(x)\n",
        "    #     return x\n",
        "\n",
        "    # Defining the forward pass  (NIN method)  \n",
        "    def forward(self, x):\n",
        "        #print(f'Input to the network: {x}')\n",
        "        x = self.pool(F.leaky_relu(self.conv1(x)))\n",
        "        x = self.pool(F.leaky_relu(self.conv2(x)))\n",
        "        x = self.pool(F.leaky_relu(self.conv3(x)))\n",
        "        #print(f'Before the weird conv layers: {x}')\n",
        "        x = F.leaky_relu(self.conv4(x))\n",
        "        x = F.leaky_relu(self.conv5(x))\n",
        "        x = self.avg_pool(self.conv6(x))\n",
        "        #print(f'After the average pooling function: {x}')\n",
        "        x = x.view(-1,2)\n",
        "        \n",
        "        \n",
        "        return x\n",
        "        \n",
        "model = CNN().to(device) # Send the CNN to the device\n",
        "\n",
        "#====================================================================\n",
        "#=================== DEFIINING VARIABLES ============================\n",
        "#====================================================================\n",
        "\n",
        "check_day = 365 * 1.5 # This is defining the timeframe for which our CNN will consider the binary output (in days) \n",
        "\n",
        "# sanity check to check progress\n",
        "counter = 0 \n",
        "\n",
        "\n",
        "# Creating empty arrays that will be appended to later\n",
        "# These will contain the patient ID and dead status (on the check day).\n",
        "training_array = []\n",
        "testing_array = []\n",
        "validation_array = []\n",
        "\n",
        "#====================================================================\n",
        "#=================== HYPER PARAMETER DEFINITION =====================\n",
        "#====================================================================\n",
        "batch_size = 4\n",
        "learning_rate = 0.001\n",
        "criterion = nn.BCEWithLogitsLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr = learning_rate)\n",
        "num_epochs = 8\n",
        "\n",
        "#====================================================================\n",
        "#=================== MAIN CODE ======================================\n",
        "#====================================================================\n",
        "\n",
        "patient_IDs, time_markers, dead_statuses = open_metadata()\n",
        "dead_patient_array, alive_patient_array = patient_status_on_check_day(check_day)\n",
        "\n",
        "#  Shuffle both arrays to ensure a random selection of patient data which will be input to the CNN\n",
        "random.shuffle(dead_patient_array)\n",
        "random.shuffle(alive_patient_array)\n",
        "\n",
        "# Equalising the length of the 'dead' and 'alive' arrays so that we can ensure optimum training proportions\n",
        "new_dead_patient_array, new_alive_patient_array = equalise_arrays(dead_patient_array, alive_patient_array)\n",
        "equalised_array_length = len(new_alive_patient_array)\n",
        "\n",
        "train_patients_dead = create_subgroup(new_dead_patient_array, equalised_array_length, 0.7)\n",
        "train_patients_alive = create_subgroup(new_alive_patient_array, equalised_array_length, 0.7)\n",
        "\n",
        "new_dead_patient_array = remove_same_elements(train_patients_dead, new_dead_patient_array)\n",
        "new_alive_patient_array = remove_same_elements(train_patients_alive, new_alive_patient_array)\n",
        "\n",
        "test_patients_dead = create_subgroup(new_dead_patient_array, equalised_array_length, 0.15)\n",
        "test_patients_alive = create_subgroup(new_alive_patient_array, equalised_array_length, 0.15)\n",
        "\n",
        "new_dead_patient_array = remove_same_elements(test_patients_dead, new_dead_patient_array)\n",
        "new_alive_patient_array = remove_same_elements(test_patients_alive, new_alive_patient_array)\n",
        "\n",
        "validate_patients_dead = create_subgroup(new_dead_patient_array, equalised_array_length, 0.15)\n",
        "validate_patients_alive = create_subgroup(new_alive_patient_array, equalised_array_length, 0.15)\n",
        "\n",
        "new_dead_patient_array = remove_same_elements(validate_patients_dead, new_dead_patient_array)\n",
        "new_alive_patient_array = remove_same_elements(validate_patients_alive, new_alive_patient_array)\n",
        "\n",
        "print(f\"After separation into training, validation and testing arrays the number of unused data is {len(new_dead_patient_array) + len(new_alive_patient_array)}. If not then something has gone wrong.\")\n",
        "\n",
        "outcomes_train, outcomes_validate, outcomes_test = create_final_datasets()\n",
        "\n",
        "training_data = ImageDataset(outcomes_train, os.path.join(project_folder, \"Textured_Masks\"), transform = transform)\n",
        "validation_data = ImageDataset(outcomes_validate, os.path.join(project_folder, \"Textured_Masks\"), transform = transform)\n",
        "test_data = ImageDataset(outcomes_test, os.path.join(project_folder, \"Textured_Masks\"), transform = transform) \n",
        "\n",
        "\n",
        "train_dataloader = DataLoader(training_data, batch_size = 4, shuffle = True)\n",
        "test_dataloader = DataLoader(test_data, batch_size = 4, shuffle = False)\n",
        "validation_dataloader = DataLoader(validation_data, batch_size = 4, shuffle = True)\n",
        "\n",
        "summary(model, (1,264,264,264), batch_size = 4)\n",
        "\n",
        "\n",
        "#============================ TRAINING AND VALIDATION LOOP ==========\n",
        "n_total_steps = len(train_dataloader)\n",
        "train_loss = []\n",
        "valid_loss = []\n",
        "avg_train_loss = np.empty(0)\n",
        "avg_valid_loss = np.empty(0)\n",
        "all_training_losses = []\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    avg_train_loss = np.append(avg_train_loss, training_loop())\n",
        "    avg_valid_loss = np.append(avg_valid_loss, validation_loop())\n",
        "\n",
        "print('FINISHED TRAINING')\n",
        "print(f'All training batch losses = {all_training_losses}')\n",
        "print(f'Training losses = {train_loss}')\n",
        "print(f'Average training losses = {avg_train_loss}')\n",
        "print(f'Validation losses = {avg_valid_loss}')\n",
        "\n",
        "#===================== PLOT LOSS CURVES =============================\n",
        "plot_loss_curves()\n",
        "\n",
        "#===================== TESTING LOOP =================================\n",
        "testing_accuracy = testing_loop()\n",
        "print(f'Accuracy on testing set = {testing_accuracy:.1f}%')"
      ]
    }
  ]
}