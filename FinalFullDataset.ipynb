{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "FinalFullDataset.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyP0kV55/F2WfcmWd7sb/hj5",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rfarwell/MPhys/blob/main/FinalFullDataset.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vAEGqXW1NkXA",
        "outputId": "9d7bbc55-c221-45e3-9950-89b1aacc424e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (1.10.0+cu111)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.7/dist-packages (0.11.1+cu111)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch) (3.10.0.2)\n",
            "Requirement already satisfied: pillow!=8.3.0,>=5.3.0 in /usr/local/lib/python3.7/dist-packages (from torchvision) (7.1.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchvision) (1.19.5)\n",
            "Requirement already satisfied: opencv-contrib-python in /usr/local/lib/python3.7/dist-packages (4.1.2.30)\n",
            "Requirement already satisfied: numpy>=1.14.5 in /usr/local/lib/python3.7/dist-packages (from opencv-contrib-python) (1.19.5)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (1.0.1)\n",
            "Requirement already satisfied: numpy>=1.14.6 in /usr/local/lib/python3.7/dist-packages (from scikit-learn) (1.19.5)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn) (3.0.0)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn) (1.4.1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn) (1.1.0)\n",
            "Collecting SimpleITK\n",
            "  Downloading SimpleITK-2.1.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (48.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 48.4 MB 19 kB/s \n",
            "\u001b[?25hInstalling collected packages: SimpleITK\n",
            "Successfully installed SimpleITK-2.1.1\n"
          ]
        }
      ],
      "source": [
        "!pip install torch torchvision\n",
        "!pip install opencv-contrib-python\n",
        "!pip install scikit-learn\n",
        "!pip install SimpleITK\n",
        "\n",
        "import numpy as np\n",
        "import random\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import SimpleITK as sitk\n",
        "import torch\n",
        "\n",
        "from mpl_toolkits.mplot3d import Axes3D\n",
        "from torch.nn import Module\n",
        "from torch.nn import Conv3d\n",
        "from torch.nn import Linear\n",
        "from torch.nn import MaxPool2d\n",
        "from torch.nn import ReLU\n",
        "from torch.nn import LogSoftmax\n",
        "from torch import flatten\n",
        "from torch import nn\n",
        "from torch import reshape\n",
        "from torch.utils.data import Dataset\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import transforms\n",
        "from torchvision import datasets\n",
        "from torch.optim import Adam\n",
        "import torchvision.models as models\n",
        "from torch.autograd import Variable"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CoKjOM5WN0hw",
        "outputId": "07573daf-8aab-4bc1-f82f-2ede36bdb2fa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Connect to GPU is available\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "print(f'Using {device} device')\n",
        "# /content/gdrive/MyDrive/MPhys/Data/COLAB-Clinical-Data.csv\n",
        "# Specify project folder location\n",
        "project_folder = \"/content/gdrive/MyDrive/Data\"\n",
        "clinical_data_filename = \"NSCLC-Radiomics-Clinical-Data.csv\"\n",
        "print(os.path.join(project_folder, clinical_data_filename))"
      ],
      "metadata": {
        "id": "b2EK94N6N2Xe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#======================= DEFINE FUNCTIONS ======================================\n",
        "\n",
        "def equalise_array_lengths(array_1, array_2) :\n",
        "  \"\"\"\n",
        "  This functions takes in the arguments of two lists and makes sure they are returned as the same length.\n",
        "\n",
        "  Rory Farwell 02/12/2021\n",
        "  \"\"\"\n",
        "  # output_array = []\n",
        "  if len(array_1) > len(array_2) :\n",
        "    array_1 = array_1[:len(array_2)]\n",
        "  elif len(array_1) < len(array_2) :\n",
        "    array_2 = array_2[:len(array_1)]\n",
        "  return (array_1, array_2)\n",
        "\n",
        "def remove_same_elements(small_array, long_array) :\n",
        "  \"\"\"\n",
        "  For use in the context, all the elements in small_array come from long_array.\n",
        "  This function will remove all of the elements used in small_array from_long_array.  \n",
        "  \"\"\"\n",
        "  for element in small_array :\n",
        "    long_array.remove(element)\n",
        "  return long_array\n",
        "\n",
        "def create_subgroup(input_array, original_array_length, desired_percentage) :\n",
        "  \"\"\"\n",
        "  This function outputs a subgroup array (e.g. training array) using a specified output array name,\n",
        "  input array and percentage length\n",
        "  \"\"\"\n",
        "  desired_length = int(original_array_length * desired_percentage)\n",
        "  output_array = random.sample(input_array, desired_length)\n",
        "  return output_array\n",
        "  \n",
        "#============================ OPEN METADATA FILE================================\n",
        "# Open the metadata.csv file, convert to an array, and remove column headers\n",
        "metadata_file = os.path.join(project_folder, clinical_data_filename)\n",
        "print(f'metadata_file path: {metadata_file}')\n",
        "metadata = np.genfromtxt(metadata_file, comments = '%', dtype=\"str\", delimiter=\",\")\n",
        "print(f\"Length of metadata array is {len(metadata)}\")\n",
        "\n",
        "#============================ RETRIEVE INFO FROM METADATA FILE =================\n",
        "patient_IDs = metadata[:,0] # selecting patient IDs from the csv file\n",
        "time_markers = metadata[:,8] # selecting the day of the last patient review from the csv file\n",
        "dead_statuses = metadata[:,9] # selecting the dead status on the last review day\n",
        "\n",
        "time_markers = time_markers.astype(np.float32) # converting to float\n",
        "dead_statuses = dead_statuses.astype(np.float32) # converting to float\n",
        "\n",
        "#============================ DEFINING VARIABLES AND CREATING EMPTY ARRAYS =====\n",
        "check_day = 365 * 1.5 # This is defining the timeframe for which our CNN will consider the binary output (in days) \n",
        "\n",
        "# sanity check to check progress\n",
        "counter = 0 \n",
        "\n",
        "# A counter of howe many patients are dead, alive or censored at the check day\n",
        "dead_counter = 0\n",
        "alive_counter = 0\n",
        "no_info_counter = 0\n",
        "\n",
        "# Empty arrays that will be appended to.\n",
        "# They will be appended with the patient IDs and dead statuses on the check day\n",
        "dead_patient_array = [] \n",
        "alive_patient_array = []\n",
        "\n",
        "# Creating empty arrays that will be appended to later\n",
        "# These will contain the patient ID and dead status (on the check day).\n",
        "training_array = []\n",
        "testing_array = []\n",
        "validation_array = []\n",
        "\n",
        "#=========================== CHECKING PATIENT DEAD STATUS ON CHECK DAY =========\n",
        "\n",
        "# The below 'for' loop will check patient status on the check day and convert if necessary.\n",
        "# Possibilites are:\n",
        "# 1) If the patient is dead and the last review point is after than the check day then\n",
        "# the patient is alive in the check day and so the dead status is changed in the new array\n",
        "# 2) If the patient is dead and the last review point is before the check day then the patient\n",
        "# is dead on the check day and their dead status is unchanged\n",
        "# 3) If the patient is alive and their last review point is after the check day then they\n",
        "# are alive at the check day and so their dead status remains unchanged\n",
        "# 4) If the patient has status alive and their last review point is before the \n",
        "# check day then we don't know if they are alive at the check day so they are ignored from the list.\n",
        "for i in range(len(dead_statuses)) :\n",
        "  temp_patient_ID = patient_IDs[i]\n",
        "  temp_dead_status = dead_statuses[i]\n",
        "  temp_time_marker = time_markers[i]\n",
        "  if temp_dead_status == 1 : #if the patient is dead\n",
        "    if temp_time_marker < check_day :#confirms that the patient was dead after time 'check_day'\n",
        "      dead_patient_array.append([temp_patient_ID, 1])\n",
        "      dead_counter += 1\n",
        "      continue\n",
        "    elif temp_time_marker > check_day :\n",
        "      alive_patient_array.append([temp_patient_ID, 0])\n",
        "      alive_counter += 1\n",
        "      continue\n",
        "  elif temp_dead_status == 0 : #if the patient is alive\n",
        "    if temp_time_marker < check_day :\n",
        "      no_info_counter += 1\n",
        "      continue\n",
        "    elif temp_time_marker > check_day :\n",
        "      alive_patient_array.append([temp_patient_ID, 0])\n",
        "      alive_counter += 1\n",
        "      continue\n",
        "\n",
        "# Printing the results of this 'for' loop (the number of dead and alive patients at the check day)\n",
        "print(f\"Dead counter after {check_day} days: {dead_counter}\")\n",
        "print(f\"Alive counter after {check_day} days: {alive_counter}\")\n",
        "print(f\"No-info counter after {check_day} days: {no_info_counter}\")\n",
        "\n",
        "#=================== SHUFFLE ALIVE AND DEAD ARRAYS =============================\n",
        "\n",
        "# Shuffle both arrays to ensure a random selection of patient data which will be input to the CNN\n",
        "random.shuffle(dead_patient_array)\n",
        "random.shuffle(alive_patient_array)\n",
        "\n",
        "#=================== EQUALISE ALIVE AND DEAD ARRAY LENGTHS =====================\n",
        "\n",
        "# Equalising the length of the 'dead' and 'alive' arrays so that we can ensure optimum training proportions\n",
        "new_dead_patient_array = equalise_array_lengths(dead_patient_array, alive_patient_array)[0]\n",
        "new_alive_patient_array = equalise_array_lengths(dead_patient_array, alive_patient_array)[1]\n",
        "print(f\"The alive and dead arrays have been sorted (randomly) so that they are both of length {len(new_dead_patient_array)}, {len(new_alive_patient_array)}\")\n",
        "\n",
        "equalised_array_length = len(new_alive_patient_array)\n",
        "\n",
        "#=================== CREATE TRAINING ARRAYS OF ALIVE AND DEAD PATIENTS =========\n",
        "train_patients_dead = create_subgroup(new_dead_patient_array, equalised_array_length, 0.7)\n",
        "train_patients_alive = create_subgroup(new_alive_patient_array, equalised_array_length, 0.7)\n",
        "# print(len(train_patients_dead))\n",
        "# print(len(train_patients_alive))\n",
        "\n",
        "new_dead_patient_array = remove_same_elements(train_patients_dead, new_dead_patient_array)\n",
        "new_alive_patient_array = remove_same_elements(train_patients_alive, new_alive_patient_array)\n",
        "# print(len(new_dead_patient_array))\n",
        "# print(len(new_alive_patient_array))\n",
        "\n",
        "#=================== CREATE TESTING ARRAYS OF ALIVE AND DEAD PATIENTS ==========\n",
        "test_patients_dead = create_subgroup(new_dead_patient_array, equalised_array_length, 0.15)\n",
        "test_patients_alive = create_subgroup(new_alive_patient_array, equalised_array_length, 0.15)\n",
        "# print(len(test_patients_dead))\n",
        "# print(len(test_patients_alive))\n",
        "\n",
        "new_dead_patient_array = remove_same_elements(test_patients_dead, new_dead_patient_array)\n",
        "new_alive_patient_array = remove_same_elements(test_patients_alive, new_alive_patient_array)\n",
        "# print(len(new_dead_patient_array))\n",
        "# print(len(new_alive_patient_array))\n",
        "\n",
        "#=================== CREATE VALIDATION ARRAYS OF ALIVE AND DEAD PATIENTS =======\n",
        "validate_patients_dead = create_subgroup(new_dead_patient_array, equalised_array_length, 0.15)\n",
        "validate_patients_alive = create_subgroup(new_alive_patient_array, equalised_array_length, 0.15)\n",
        "# print(len(validate_patients_dead))\n",
        "# print(len(validate_patients_alive))\n",
        "\n",
        "new_dead_patient_array = remove_same_elements(validate_patients_dead, new_dead_patient_array)\n",
        "new_alive_patient_array = remove_same_elements(validate_patients_alive, new_alive_patient_array)\n",
        "# print(len(new_dead_patient_array))\n",
        "# print(len(new_alive_patient_array))\n",
        "\n",
        "#=================== COMBINE THE ALIVE AND DEAD ARRAYS TO PRODUCE TOTAL TRAINING, TESTING AND VALIDATION ARRAYS ======\n",
        "outcomes_train = train_patients_dead + train_patients_alive\n",
        "outcomes_test = test_patients_dead + test_patients_alive\n",
        "outcomes_validate = validate_patients_dead + validate_patients_alive\n",
        "\n",
        "#=================== SHUFFLE THE TOTAL TRAINING, TESTING AND VALIDATION ARRAYS ==========\n",
        "random.shuffle(outcomes_train)\n",
        "random.shuffle(outcomes_test)\n",
        "random.shuffle(outcomes_validate)\n",
        "\n",
        "print(f'Length of shuffled outcomes_train: {len(outcomes_train)}') \n",
        "print(f'Length of shuffled outcomes_validate: {len(outcomes_validate)}')\n",
        "print(f'Length of shuffled outcomes_test: {len(outcomes_test)}')\n",
        "\n",
        "print(outcomes_train)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-SbIjxSLN41W",
        "outputId": "870d7d31-7236-4bbe-dcd4-26e497b3df5a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "metadata_file path: /content/gdrive/MyDrive/Data/NSCLC-Radiomics-Clinical-Data.csv\n",
            "Length of metadata array is 400\n",
            "Dead counter after 547.5 days: 200\n",
            "Alive counter after 547.5 days: 200\n",
            "No-info counter after 547.5 days: 0\n",
            "The alive and dead arrays have been sorted (randomly) so that they are both of length 200, 200\n",
            "Length of shuffled outcomes_train: 280\n",
            "Length of shuffled outcomes_validate: 60\n",
            "Length of shuffled outcomes_test: 60\n",
            "[['LUNG1-016', 1], ['LUNG1-079', 1], ['LUNG1-261', 0], ['LUNG1-185', 0], ['LUNG1-032', 1], ['LUNG1-124', 1], ['LUNG1-039', 1], ['LUNG1-219', 0], ['LUNG1-064', 0], ['LUNG1-209', 0], ['LUNG1-178', 0], ['LUNG1-020', 1], ['LUNG1-029', 1], ['LUNG1-131', 1], ['LUNG1-215', 1], ['LUNG1-226', 1], ['LUNG1-377', 1], ['LUNG1-269', 1], ['LUNG1-374', 1], ['LUNG1-190', 0], ['LUNG1-109', 1], ['LUNG1-186', 0], ['LUNG1-352', 1], ['LUNG1-063', 0], ['LUNG1-006', 1], ['LUNG1-071', 0], ['LUNG1-024', 0], ['LUNG1-341', 0], ['LUNG1-118', 0], ['LUNG1-331', 0], ['LUNG1-152', 0], ['LUNG1-129', 0], ['LUNG1-045', 0], ['LUNG1-322', 0], ['LUNG1-366', 1], ['LUNG1-025', 0], ['LUNG1-289', 0], ['LUNG1-233', 1], ['LUNG1-382', 0], ['LUNG1-189', 1], ['LUNG1-072', 1], ['LUNG1-241', 1], ['LUNG1-085', 1], ['LUNG1-033', 1], ['LUNG1-422', 0], ['LUNG1-091', 1], ['LUNG1-011', 1], ['LUNG1-002', 1], ['LUNG1-292', 1], ['LUNG1-001', 0], ['LUNG1-248', 1], ['LUNG1-216', 1], ['LUNG1-270', 1], ['LUNG1-151', 1], ['LUNG1-125', 1], ['LUNG1-040', 0], ['LUNG1-395', 1], ['LUNG1-212', 0], ['LUNG1-044', 1], ['LUNG1-268', 1], ['LUNG1-393', 0], ['LUNG1-218', 0], ['LUNG1-300', 0], ['LUNG1-342', 1], ['LUNG1-179', 1], ['LUNG1-052', 1], ['LUNG1-328', 0], ['LUNG1-372', 0], ['LUNG1-048', 0], ['LUNG1-222', 0], ['LUNG1-156', 0], ['LUNG1-247', 0], ['LUNG1-274', 1], ['LUNG1-023', 1], ['LUNG1-169', 0], ['LUNG1-103', 0], ['LUNG1-136', 1], ['LUNG1-390', 0], ['LUNG1-388', 0], ['LUNG1-182', 0], ['LUNG1-057', 1], ['LUNG1-279', 0], ['LUNG1-197', 1], ['LUNG1-293', 0], ['LUNG1-018', 0], ['LUNG1-250', 0], ['LUNG1-235', 0], ['LUNG1-284', 1], ['LUNG1-015', 0], ['LUNG1-255', 1], ['LUNG1-265', 0], ['LUNG1-019', 1], ['LUNG1-368', 0], ['LUNG1-334', 0], ['LUNG1-170', 1], ['LUNG1-349', 1], ['LUNG1-164', 0], ['LUNG1-007', 1], ['LUNG1-383', 1], ['LUNG1-319', 0], ['LUNG1-275', 1], ['LUNG1-200', 1], ['LUNG1-167', 0], ['LUNG1-172', 1], ['LUNG1-022', 1], ['LUNG1-157', 0], ['LUNG1-415', 0], ['LUNG1-198', 1], ['LUNG1-362', 0], ['LUNG1-243', 0], ['LUNG1-333', 0], ['LUNG1-365', 1], ['LUNG1-148', 1], ['LUNG1-311', 0], ['LUNG1-122', 0], ['LUNG1-014', 0], ['LUNG1-149', 1], ['LUNG1-287', 1], ['LUNG1-236', 0], ['LUNG1-220', 1], ['LUNG1-223', 0], ['LUNG1-256', 1], ['LUNG1-283', 0], ['LUNG1-412', 1], ['LUNG1-376', 1], ['LUNG1-359', 1], ['LUNG1-291', 0], ['LUNG1-195', 0], ['LUNG1-240', 0], ['LUNG1-046', 1], ['LUNG1-410', 1], ['LUNG1-138', 0], ['LUNG1-205', 1], ['LUNG1-258', 0], ['LUNG1-176', 1], ['LUNG1-266', 1], ['LUNG1-100', 0], ['LUNG1-132', 0], ['LUNG1-217', 1], ['LUNG1-364', 0], ['LUNG1-405', 0], ['LUNG1-260', 1], ['LUNG1-126', 1], ['LUNG1-396', 0], ['LUNG1-263', 0], ['LUNG1-115', 1], ['LUNG1-308', 1], ['LUNG1-187', 0], ['LUNG1-135', 0], ['LUNG1-026', 1], ['LUNG1-155', 1], ['LUNG1-089', 0], ['LUNG1-413', 1], ['LUNG1-077', 1], ['LUNG1-278', 1], ['LUNG1-139', 0], ['LUNG1-061', 0], ['LUNG1-147', 0], ['LUNG1-206', 1], ['LUNG1-229', 1], ['LUNG1-409', 0], ['LUNG1-163', 1], ['LUNG1-379', 0], ['LUNG1-370', 1], ['LUNG1-329', 1], ['LUNG1-296', 1], ['LUNG1-160', 0], ['LUNG1-090', 1], ['LUNG1-414', 1], ['LUNG1-031', 0], ['LUNG1-369', 1], ['LUNG1-389', 1], ['LUNG1-318', 1], ['LUNG1-344', 0], ['LUNG1-161', 0], ['LUNG1-062', 1], ['LUNG1-355', 0], ['LUNG1-230', 0], ['LUNG1-098', 1], ['LUNG1-225', 1], ['LUNG1-356', 1], ['LUNG1-325', 0], ['LUNG1-095', 1], ['LUNG1-234', 0], ['LUNG1-141', 1], ['LUNG1-298', 0], ['LUNG1-299', 0], ['LUNG1-404', 1], ['LUNG1-281', 0], ['LUNG1-146', 1], ['LUNG1-326', 1], ['LUNG1-314', 0], ['LUNG1-273', 0], ['LUNG1-402', 0], ['LUNG1-120', 0], ['LUNG1-330', 0], ['LUNG1-271', 0], ['LUNG1-421', 1], ['LUNG1-211', 0], ['LUNG1-180', 0], ['LUNG1-092', 0], ['LUNG1-350', 1], ['LUNG1-008', 1], ['LUNG1-037', 1], ['LUNG1-309', 1], ['LUNG1-253', 1], ['LUNG1-193', 0], ['LUNG1-327', 1], ['LUNG1-012', 1], ['LUNG1-420', 0], ['LUNG1-272', 1], ['LUNG1-214', 1], ['LUNG1-251', 0], ['LUNG1-264', 0], ['LUNG1-127', 1], ['LUNG1-245', 0], ['LUNG1-158', 1], ['LUNG1-304', 0], ['LUNG1-097', 1], ['LUNG1-257', 0], ['LUNG1-041', 1], ['LUNG1-177', 0], ['LUNG1-080', 0], ['LUNG1-332', 0], ['LUNG1-228', 0], ['LUNG1-054', 0], ['LUNG1-188', 0], ['LUNG1-074', 0], ['LUNG1-297', 0], ['LUNG1-237', 0], ['LUNG1-399', 0], ['LUNG1-084', 0], ['LUNG1-398', 0], ['LUNG1-252', 1], ['LUNG1-036', 1], ['LUNG1-196', 1], ['LUNG1-384', 0], ['LUNG1-028', 1], ['LUNG1-107', 1], ['LUNG1-276', 0], ['LUNG1-249', 0], ['LUNG1-184', 0], ['LUNG1-165', 0], ['LUNG1-360', 0], ['LUNG1-088', 1], ['LUNG1-285', 1], ['LUNG1-254', 0], ['LUNG1-130', 0], ['LUNG1-060', 1], ['LUNG1-201', 0], ['LUNG1-173', 1], ['LUNG1-232', 0], ['LUNG1-117', 1], ['LUNG1-351', 1], ['LUNG1-262', 1], ['LUNG1-053', 1], ['LUNG1-078', 0], ['LUNG1-113', 0], ['LUNG1-005', 1], ['LUNG1-004', 1], ['LUNG1-192', 1], ['LUNG1-280', 0], ['LUNG1-050', 1], ['LUNG1-400', 1], ['LUNG1-204', 1], ['LUNG1-202', 1], ['LUNG1-010', 0], ['LUNG1-354', 0], ['LUNG1-418', 1], ['LUNG1-238', 0], ['LUNG1-407', 1], ['LUNG1-106', 1], ['LUNG1-153', 0], ['LUNG1-357', 0], ['LUNG1-099', 1], ['LUNG1-302', 0], ['LUNG1-375', 1], ['LUNG1-305', 1], ['LUNG1-051', 1], ['LUNG1-239', 0]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from torchvision.io import read_image\n",
        "\n",
        "# Normalize class added at 10pm 12/12/2021\n",
        "class Normalize():\n",
        "  def __init__(self):\n",
        "    pass\n",
        "  \n",
        "  # def __call__(self, sample):\n",
        "  #   inputs, targets = sample\n",
        "  #   inputs = transforms.Normalize(mean = 0.5, std = 0.5)\n",
        "  #   return inputs, targets\n",
        "  def __call__(self,vol):\n",
        "    vol =((vol-(vol.mean()))/vol.std()) + 1\n",
        "    return vol\n",
        "\n",
        "# transform = transforms.Compose(\n",
        "#     [transforms.ToTensor(), transforms.Normalize(mean = 0.5, std = 0.5)] #added at 10:31pm 13/12/2021 to normalize the inputs\n",
        "# )\n",
        "\n",
        "transform = transforms.Compose(\n",
        "    [transforms.ToTensor(), Normalize() ] #added at 11:00pm 13/12/2021 to normalize the inputs. THIS NORMALIZES to mean = 0 and std = -1\n",
        ")\n",
        "\n",
        "\n",
        "class ImageDataset(Dataset) :\n",
        "  def __init__(self, annotations, img_dir, transform = transform, target_transform = None) :\n",
        "    self.img_labels = annotations\n",
        "    self.img_dir = img_dir\n",
        "    self.transform = transform\n",
        "    self.target_transform = target_transform\n",
        "\n",
        "  def __len__(self) :\n",
        "    return len(self.img_labels)\n",
        "\n",
        "  def __getitem__(self,idx) :\n",
        "    img_path = os.path.join(self.img_dir, self.img_labels[idx][0] + \"-GTV-1.nii\" )\n",
        "    image_sitk = sitk.ReadImage(img_path)\n",
        "    # ID = self.img_labels[idx][0]\n",
        "    # print(f'ID: {ID}')\n",
        "    image = sitk.GetArrayFromImage(image_sitk)\n",
        "    label = self.img_labels[idx][1]\n",
        "    if self.transform :\n",
        "      image = self.transform(image)\n",
        "    if self.target_transform :\n",
        "      label = self.target_transform(label)\n",
        "    return image,label\n",
        "\n",
        "# training_data = ImageDataset(outcomes_train, os.path.join(project_folder, \"Textured_Masks\"), transform = transforms.ToTensor())\n",
        "# validation_data = ImageDataset(outcomes_validate, os.path.join(project_folder, \"Textured_Masks\"), transform = transforms.ToTensor())\n",
        "# test_data = ImageDataset(outcomes_test, os.path.join(project_folder, \"Textured_Masks\"), transform = transforms.ToTensor())\n",
        "\n",
        "training_data = ImageDataset(outcomes_train, os.path.join(project_folder, \"Textured_Masks\"), transform = transform)\n",
        "validation_data = ImageDataset(outcomes_validate, os.path.join(project_folder, \"Textured_Masks\"), transform = transform)\n",
        "test_data = ImageDataset(outcomes_test, os.path.join(project_folder, \"Textured_Masks\"), transform = transform) \n",
        "\n"
      ],
      "metadata": {
        "id": "2Cdw0AEyN77K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 4\n",
        "train_dataloader = DataLoader(training_data, batch_size = 4, shuffle = True)\n",
        "test_dataloader = DataLoader(test_data, batch_size = 4, shuffle = False)\n",
        "validation_dataloader = DataLoader(validation_data, batch_size = 4, shuffle = True)\n",
        "\n",
        "print(len(train_dataloader))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FHud7JurOyhe",
        "outputId": "ebfe2be1-8916-4eab-88e0-95954f99718d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "70\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "# The network below is copied from Patrick's GitHub. It will be used since, when\n",
        "# he ran it on the reduced dataset, the validation loss went down. It will now \n",
        "# be used on the full dataset\n",
        "class CNN(nn.Module):   \n",
        "    def __init__(self):\n",
        "        super(CNN, self).__init__()\n",
        "        self.conv1 = nn.Conv3d(1,4,2,2)\n",
        "        self.pool = nn.MaxPool3d(2,2)\n",
        "        self.conv2 = nn.Conv3d(4,16,2,2)\n",
        "        self.conv3 = nn.Conv3d(16,64,2,2)\n",
        "        self.conv4 = nn.Conv3d(64,256,2,2)\n",
        "        self.dropout = nn.Dropout(0.25)\n",
        "        self.fc1 = nn.Linear(256,64)\n",
        "        self.fc2 = nn.Linear(64,16)\n",
        "        self.fc3 = nn.Linear(16,2)\n",
        "\n",
        "    # Defining the forward pass    \n",
        "    def forward(self, x):\n",
        "        x = self.pool(F.leaky_relu(self.conv1(x)))\n",
        "        x = self.pool(F.leaky_relu(self.conv2(x)))\n",
        "        x = self.pool(F.leaky_relu(self.conv3(x)))\n",
        "        x = self.pool(F.leaky_relu(self.conv4(x)))\n",
        "        x = x.view(-1, 256)\n",
        "        x = self.dropout(x)\n",
        "        x = F.leaky_relu(self.fc1(x))\n",
        "        x = self.dropout(x)\n",
        "        x = F.leaky_relu(self.fc2(x))\n",
        "        x = self.dropout(x)\n",
        "        x = self.fc3(x)\n",
        "        # return F.leaky_relu(x)\n",
        "        return x\n",
        "\n",
        "# class Model(torch.nn.Module): \n",
        "#     def __init__(self):\n",
        "#         super(Model, self).__init__()\n",
        "#         self.conv1 = nn.Conv3d(in_channels=1, out_channels=8, kernel_size=3, stride = 2)\n",
        "#         self.conv2 = nn.Conv3d(in_channels=8, out_channels=8, kernel_size=3, stride = 2)\n",
        "#         self.conv3 = nn.Conv3d(in_channels=8, out_channels=16, kernel_size=3, stride = 2)\n",
        "#         self.conv4 = nn.Conv3d(in_channels=16, out_channels=16, kernel_size=3, stride = 2)\n",
        "#         self.fc1 = nn.Linear(432, 2)\n",
        "        \n",
        "\n",
        "#     def forward(self, x):\n",
        "#         x = F.relu(self.conv1(x))\n",
        "#         x = F.relu(self.conv2(x))\n",
        "#         x = F.max_pool3d(x, kernel_size=2, stride=2)\n",
        "\n",
        "#         x = F.relu(self.conv3(x))\n",
        "#         x = F.relu(self.conv4(x))\n",
        "#         x = F.max_pool3d(x, kernel_size=2, stride=2)\n",
        "\n",
        "#         x = torch.flatten(x, start_dim=1)\n",
        "#         x = self.fc1(x)\n",
        "#         return x\n",
        "  \n",
        "model = CNN().to(device)"
      ],
      "metadata": {
        "id": "lbGqj1ZDO2zl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torchsummary import summary\n",
        "summary(model, (1,264,264,264), batch_size = 4)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DgSff-lyPewQ",
        "outputId": "4adf4c3c-e129-420d-87f6-895ee3138ce9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv3d-1      [4, 4, 132, 132, 132]              36\n",
            "         MaxPool3d-2         [4, 4, 66, 66, 66]               0\n",
            "            Conv3d-3        [4, 16, 33, 33, 33]             528\n",
            "         MaxPool3d-4        [4, 16, 16, 16, 16]               0\n",
            "            Conv3d-5           [4, 64, 8, 8, 8]           8,256\n",
            "         MaxPool3d-6           [4, 64, 4, 4, 4]               0\n",
            "            Conv3d-7          [4, 256, 2, 2, 2]         131,328\n",
            "         MaxPool3d-8          [4, 256, 1, 1, 1]               0\n",
            "           Dropout-9                   [4, 256]               0\n",
            "           Linear-10                    [4, 64]          16,448\n",
            "          Dropout-11                    [4, 64]               0\n",
            "           Linear-12                    [4, 16]           1,040\n",
            "          Dropout-13                    [4, 16]               0\n",
            "           Linear-14                     [4, 2]              34\n",
            "================================================================\n",
            "Total params: 157,670\n",
            "Trainable params: 157,670\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 280.76\n",
            "Forward/backward pass size (MB): 336.61\n",
            "Params size (MB): 0.60\n",
            "Estimated Total Size (MB): 617.97\n",
            "----------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# loss and optimizer\n",
        "learning_rate = 0.001\n",
        "criterion = nn.BCEWithLogitsLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr = learning_rate)"
      ],
      "metadata": {
        "id": "bnPgkkXxPfnm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#training_loop\n",
        "num_epochs = 8\n",
        "n_total_steps = len(train_dataloader)\n",
        "train_loss = []\n",
        "valid_loss = []\n",
        "avg_train_loss = np.empty(0)\n",
        "avg_valid_loss = np.empty(0)\n",
        "all_training_losses = []\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "  # ======================================= TRAINING LOOP ======================================\n",
        "  epoch_train_loss = 0 # will be used for plotting test vs valid loss curves\n",
        "  n_training_samples = 0\n",
        "\n",
        "  print(f'Training for epoch {epoch+1}')\n",
        "  print('=============================================')\n",
        "  \n",
        "  model.train()\n",
        "  for i, (images, labels) in enumerate(train_dataloader):\n",
        "    # Reformatting input images to have 5 dimensions and casting to a float\n",
        "    images = reshape(images, (images.shape[0],1 ,264,264,264))\n",
        "    images = images.float()\n",
        "\n",
        "\n",
        "    # turning labels of size one to one-hot labels \n",
        "    # e.g labels = (1,0,0,1) --> hot_labels [(0,1), (1,0), (1,0), 0,1]\n",
        "    # This is need because nn.BCELogitsWithLoss() expects inputs of this format\n",
        "    hot_labels = torch.empty((images.shape[0], 2))\n",
        "    for index in range(len(labels)):\n",
        "          if labels[index] == 0 :\n",
        "            hot_labels[index,0] = 1\n",
        "            hot_labels[index,1] = 0\n",
        "          elif labels[index] == 1 :\n",
        "            hot_labels[index,0] = 0\n",
        "            hot_labels[index,1] = 1\n",
        "    \n",
        "    \n",
        "    # Send images and one-hot labels to the device (cuda/GPU)\n",
        "    images = images.to(device)\n",
        "    hot_labels = hot_labels.to(device)\n",
        "\n",
        "\n",
        "    # Forward pass\n",
        "    outputs = model(images)\n",
        "    # print(outputs)\n",
        "    loss = criterion(outputs, hot_labels)\n",
        "    \n",
        "\n",
        "    # Backwards pass\n",
        "    optimizer.zero_grad() # Clear gradients before \n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    # Add the number of images in this batch to n_training_samples which will\n",
        "    # be used when calculating the average loss per image in the training set\n",
        "    n_training_samples += labels.shape[0]\n",
        "    #print(f'Number of samples completed after {i+1} batches = {n_training_samples}')\n",
        "    \n",
        "\n",
        "    # Updating the total training loss of this epoch\n",
        "    # Printing loss for current batch and the new updated total\n",
        "    # training loss for this epoch\n",
        "    #print(f'Loss of batch {i+1} = {loss.item():.2f}')\n",
        "    all_training_losses.append(loss.item())\n",
        "    epoch_train_loss += loss.item()\n",
        "    #print(f'Total training loss after batch {i+1} = {epoch_train_loss:.2f}')\n",
        "    \n",
        "\n",
        "    # Print a progress statement to ensure the network is running\n",
        "    if (i+1)%7 == 0 :\n",
        "      print(f'Epoch {epoch+1}/{num_epochs}, step {i+1}/{n_total_steps}, loss = {loss.item():.4f}')\n",
        "  \n",
        "  # Append the train_loss list with the total training loss for this epoch\n",
        "  train_loss.append(epoch_train_loss)\n",
        "\n",
        "  # Append the avg_train_loss list with the average training loss of this epoch\n",
        "  avg_train_loss = np.append(avg_train_loss, epoch_train_loss/n_training_samples)\n",
        "  print(f\"avg train loss {avg_train_loss}\")\n",
        "\n",
        "  print(f'Training loss array at end of epoch {epoch + 1}: {train_loss}. Total number of images used = {n_training_samples}')\n",
        "  print(f'Finished training for epoch {epoch+1}')\n",
        "\n",
        "  \n",
        "  \n",
        "  #================================================ VALIDATION LOOP =================================================\n",
        "  print(f'Validation for epoch {epoch+1}')\n",
        "  print('=============================================')\n",
        "  model.eval()\n",
        "  with torch.no_grad(): # ensuring gradients are not calculated during the validation loop\n",
        "    valid_epoch_loss = 0\n",
        "    n_valid_correct = 0\n",
        "    n_valid_samples = 0\n",
        "    for images, labels in validation_dataloader :\n",
        "      images = images = reshape(images, (images.shape[0],1 ,264,264,264))\n",
        "      images = images.float()\n",
        "      hot_labels = torch.empty((images.shape[0], 2))\n",
        "      #print(new_labels.shape)\n",
        "      for index in range(len(labels)):\n",
        "          if labels[index] == 0 :\n",
        "            hot_labels[index,0] = 1\n",
        "            hot_labels[index,1] = 0\n",
        "          elif labels[index] == 1 :\n",
        "            hot_labels[index,0] = 0\n",
        "            hot_labels[index,1] = 1\n",
        "      images = images.to(device)\n",
        "      hot_labels = hot_labels.to(device)\n",
        "      outputs = model(images)\n",
        "      # calculate loss of validation set\n",
        "      loss = criterion(outputs, hot_labels)\n",
        "      valid_epoch_loss += loss.item()\n",
        "\n",
        "      # max returns (value, index) \n",
        "      _,predictions = torch.max(outputs, 1)\n",
        "      _,targets = torch.max(hot_labels, 1)\n",
        "      #print(f'predictions: {predictions}')\n",
        "      #print(f'targets: {targets}')\n",
        "      #print(f'correct in this batch: {(predictions == targets).sum().item()}')\n",
        "      n_valid_samples += labels.shape[0]\n",
        "      n_valid_correct += (predictions == targets).sum().item()\n",
        "      #print(f'n_correct = {n_correct}. n_samples = {n_samples}')\n",
        "    avg_valid_loss = np.append(avg_valid_loss, valid_epoch_loss/n_valid_samples)\n",
        "    #valid_loss.append(valid_epoch_loss)\n",
        "    acc = (100*n_valid_correct)/n_valid_samples\n",
        "    print(f'Accuracy on validation set for epoch {epoch+1} = {acc:.1f}%')\n",
        "    print(f'Loss on validation set = {valid_epoch_loss}')\n",
        "\n",
        "    print(f'Finished validation for epoch {epoch+1}')\n",
        "    print('=============================================')\n",
        "\n",
        "    #================================================ TENSORBOARD STUFF ===============================================\n",
        "  \n",
        "\n",
        "  # tb.add_histogram(\"conv1.bias\", model.conv1.bias, epoch)\n",
        "  # tb.add_histogram(\"conv1.weight\", model.conv1.weight, epoch)\n",
        "  # tb.add_histogram(\"conv2.bias\", model.conv2.bias, epoch)\n",
        "  # tb.add_histogram(\"conv2.weight\", model.conv2.weight, epoch)\n",
        "  # tb.add_histogram(\"conv3.bias\", model.conv3.bias, epoch)\n",
        "  # tb.add_histogram(\"conv3.weight\", model.conv3.weight, epoch)\n",
        "  # tb.add_histogram(\"conv4.bias\", model.conv4.bias, epoch)\n",
        "  # tb.add_histogram(\"conv4.weight\", model.conv4.weight, epoch)\n",
        "  # tb.add_histogram(\"fc1.bias\", model.fc1.bias, epoch)\n",
        "  # tb.add_histogram(\"fc1.weight\", model.fc1.weight, epoch)\n",
        "  # tb.add_histogram(\"fc2.bias\", model.fc2.bias, epoch)\n",
        "  # tb.add_histogram(\"fc2.weight\", model.fc2.weight, epoch)\n",
        "  # tb.add_histogram(\"fc3.bias\", model.fc3.bias, epoch)\n",
        "  # tb.add_histogram(\"fc3.weight\", model.fc3.weight, epoch)\n",
        "  # tb.add_scalar(\"training_loss\", avg_train_loss[epoch], epoch)\n",
        "  # tb.add_scalar(\"validation_loss\", avg_valid_loss[epoch], epoch)\n",
        "\n",
        "    # tb.add_scalar(\"Validation loss\", (valid_epoch_loss/n_valid_samples), epoch)\n",
        "\n",
        "# close tensorboard once the code has training loop has finished running\n",
        "# tb.close() \n",
        "\n",
        "print('FINISHED TRAINING')\n",
        "print(f'All training batch losses = {all_training_losses}')\n",
        "print(f'Training losses = {train_loss}')\n",
        "print(f'Average training losses = {avg_train_loss}')\n",
        "print(f'Validation losses = {avg_valid_loss}')\n",
        "#testing\n",
        "# with torch.no_grad():\n",
        "#     n_correct = 0\n",
        "#     n_samples = 0\n",
        "#     for images, labels in test_dataloader :\n",
        "#       images = images = reshape(images, (images.shape[0],1 ,264,264,264))\n",
        "#       images = images.float()\n",
        "#       hot_labels = torch.empty((images.shape[0], 2))\n",
        "#       #print(new_labels.shape)\n",
        "#       for index in range(len(labels)):\n",
        "#           if labels[index] == 0 :\n",
        "#             hot_labels[index,0] = 1\n",
        "#             hot_labels[index,1] = 0\n",
        "#           elif labels[index] == 1 :\n",
        "#             hot_labels[index,0] = 0\n",
        "#             hot_labels[index,1] = 1\n",
        "#       images = images.to(device)\n",
        "#       hot_labels = hot_labels.to(device)\n",
        "#       outputs = model(images)\n",
        "#       # max returns (value, index) \n",
        "#       _,predictions = torch.max(outputs, 1)\n",
        "#       _,targets = torch.max(hot_labels,1)\n",
        "#       #print(f'predictions: {predictions}')\n",
        "#       #print(f'targets: {targets}')\n",
        "#       n_samples += hot_labels.shape[0]\n",
        "#       n_correct += (predictions == targets).sum().item()\n",
        "#       #print(f'n_correct = {n_correct}. n_samples = {n_samples}')\n",
        "    \n",
        "#     acc = (100*n_correct)/n_samples\n",
        "#     print(f'Accuracy on testing set = {acc:.1f}%')\n",
        "\n",
        "\n",
        "# time renewal\n",
        "# tb.close()\n",
        "# time renewal counter: 1 2 3 4 5 6 7 8 "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 414
        },
        "id": "N-AFyEGBPtRA",
        "outputId": "a0c26c99-7546-4b62-ee97-88d46542a8b9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training for epoch 1\n",
            "=============================================\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-0e692a6a4390>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m   \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m   \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m     \u001b[0;31m# Reformatting input images to have 5 dimensions and casting to a float\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0mimages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0;36m264\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m264\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m264\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    519\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    520\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 521\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    522\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    559\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    560\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 561\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    562\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    563\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-7-1c11b1e20eb2>\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     36\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m     \u001b[0mimg_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimg_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimg_labels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"-GTV-1.nii\"\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m     \u001b[0mimage_sitk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msitk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mReadImage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m     \u001b[0;31m# ID = self.img_labels[idx][0]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[0;31m# print(f'ID: {ID}')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/SimpleITK/extra.py\u001b[0m in \u001b[0;36mReadImage\u001b[0;34m(fileName, outputPixelType, imageIO)\u001b[0m\n\u001b[1;32m    344\u001b[0m     \u001b[0mreader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSetImageIO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimageIO\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    345\u001b[0m     \u001b[0mreader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSetOutputPixelType\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputPixelType\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 346\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mreader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    347\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    348\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/SimpleITK/SimpleITK.py\u001b[0m in \u001b[0;36mExecute\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   8013\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   8014\u001b[0m         \"\"\"\n\u001b[0;32m-> 8015\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_SimpleITK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mImageFileReader_Execute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   8016\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   8017\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mReadImageInformation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Exception thrown in SimpleITK ImageFileReader_Execute: /tmp/SimpleITK/Code/IO/src/sitkImageReaderBase.cxx:105:\nsitk::ERROR: Unable to determine ImageIO reader for \"/content/gdrive/MyDrive/Data/Textured_Masks/LUNG1-344-GTV-1.nii\""
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# testing\n",
        "with torch.no_grad():\n",
        "    n_correct = 0\n",
        "    n_samples = 0\n",
        "    counter = 0\n",
        "    for images, labels in test_dataloader :\n",
        "      counter+=1\n",
        "      print(counter)\n",
        "      images = images = reshape(images, (images.shape[0],1 ,264,264,264))\n",
        "      images = images.float()\n",
        "      hot_labels = torch.empty((images.shape[0], 2))\n",
        "      #print(new_labels.shape)\n",
        "      for index in range(len(labels)):\n",
        "          if labels[index] == 0 :\n",
        "            hot_labels[index,0] = 1\n",
        "            hot_labels[index,1] = 0\n",
        "          elif labels[index] == 1 :\n",
        "            hot_labels[index,0] = 0\n",
        "            hot_labels[index,1] = 1\n",
        "      images = images.to(device)\n",
        "      hot_labels = hot_labels.to(device)\n",
        "      outputs = model(images)\n",
        "      # max returns (value, index) \n",
        "      _,predictions = torch.max(outputs, 1)\n",
        "      _,targets = torch.max(hot_labels,1)\n",
        "      #print(f'predictions: {predictions}')\n",
        "      #print(f'targets: {targets}')\n",
        "      n_samples += hot_labels.shape[0]\n",
        "      n_correct += (predictions == targets).sum().item()\n",
        "      #print(f'n_correct = {n_correct}. n_samples = {n_samples}')\n",
        "    \n",
        "    acc = (100*n_correct)/n_samples\n",
        "    print(f'Accuracy on testing set = {acc:.1f}%')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 381
        },
        "id": "0FxZEolvgg2V",
        "outputId": "05c2ddf8-7c70-4235-b8b8-95e23e5808ca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-23ce65d574e5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mn_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mcounter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtest_dataloader\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m       \u001b[0mcounter\u001b[0m\u001b[0;34m+=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m       \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcounter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    519\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    520\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 521\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    522\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    559\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    560\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 561\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    562\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    563\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-6-1c11b1e20eb2>\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     36\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m     \u001b[0mimg_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimg_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimg_labels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"-GTV-1.nii\"\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m     \u001b[0mimage_sitk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msitk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mReadImage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m     \u001b[0;31m# ID = self.img_labels[idx][0]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[0;31m# print(f'ID: {ID}')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/SimpleITK/extra.py\u001b[0m in \u001b[0;36mReadImage\u001b[0;34m(fileName, outputPixelType, imageIO)\u001b[0m\n\u001b[1;32m    344\u001b[0m     \u001b[0mreader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSetImageIO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimageIO\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    345\u001b[0m     \u001b[0mreader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSetOutputPixelType\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputPixelType\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 346\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mreader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    347\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    348\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/SimpleITK/SimpleITK.py\u001b[0m in \u001b[0;36mExecute\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   8013\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   8014\u001b[0m         \"\"\"\n\u001b[0;32m-> 8015\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_SimpleITK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mImageFileReader_Execute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   8016\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   8017\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mReadImageInformation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Exception thrown in SimpleITK ImageFileReader_Execute: /tmp/SimpleITK/Code/IO/src/sitkImageReaderBase.cxx:105:\nsitk::ERROR: Unable to determine ImageIO reader for \"/content/gdrive/MyDrive/Data/Textured_Masks/LUNG1-201-GTV-1.nii\""
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# avg_valid_loss = []\n",
        "# for i in range(len(valid_loss)):\n",
        "#   avg_valid_loss.append(valid_loss[i]/n_valid_samples)\n",
        "\n",
        "# print(n_valid_samples)\n",
        "# print(avg_valid_loss)"
      ],
      "metadata": {
        "id": "bPu9uUriP1Bo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(avg_train_loss)\n",
        "print(avg_valid_loss)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EQtLe2AAJDsX",
        "outputId": "11f51298-865b-4518-8ba4-0f4ea91d0f97"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.17399236 0.172626   0.16773557 0.15693387 0.15177978 0.12418741\n",
            " 0.08705412 0.08911693 0.05246835 0.04037671]\n",
            "[0.17244352 0.171502   0.16443949 0.16792054 0.16465756 0.18276866\n",
            " 0.26117081 0.22296306 0.39223762 0.42991074]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "new_avg_train_loss = avg_train_loss\n",
        "new_avg_valid_loss = avg_valid_loss\n",
        "\n",
        "epochs = np.array(range(num_epochs)) + 1\n",
        "fig = plt.figure()\n",
        "plt.xticks(fontsize=20)\n",
        "plt.yticks(fontsize=20)\n",
        "fig.set_size_inches(20, 10)\n",
        "# plt.plot(epochs, avg_train_loss, label = 'Average training loss',linewidth=7.0)\n",
        "plt.plot(epochs, new_avg_train_loss, label = 'Average training loss',linewidth=7.0)\n",
        "plt.plot(epochs, new_avg_valid_loss, label = 'Average validation loss',linewidth=7.0)\n",
        "plt.legend(loc='best', prop={'size': 20})\n",
        "plt.ylabel('Average Loss', fontsize = 20)\n",
        "plt.xlabel('Epoch Number', fontsize = 20)\n",
        "plt.show()\n",
        "print(f'The accuracy of the network on the test set of length {len(test_dataloader) * batch_size} was {acc:.1f}%')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 948
        },
        "id": "ekIfYNQOJPig",
        "outputId": "21c08f26-69a4-4088-d780-ca1892816100"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-f0250283b6bb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m# plt.plot(epochs, avg_train_loss, label = 'Average training loss',linewidth=7.0)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_avg_train_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'Average training loss'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlinewidth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m7.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_avg_valid_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'Average validation loss'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlinewidth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m7.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'best'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'size'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mylabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Average Loss'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfontsize\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/matplotlib/pyplot.py\u001b[0m in \u001b[0;36mplot\u001b[0;34m(scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2761\u001b[0m     return gca().plot(\n\u001b[1;32m   2762\u001b[0m         *args, scalex=scalex, scaley=scaley, **({\"data\": data} if data\n\u001b[0;32m-> 2763\u001b[0;31m         is not None else {}), **kwargs)\n\u001b[0m\u001b[1;32m   2764\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2765\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/matplotlib/axes/_axes.py\u001b[0m in \u001b[0;36mplot\u001b[0;34m(self, scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1645\u001b[0m         \"\"\"\n\u001b[1;32m   1646\u001b[0m         \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcbook\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormalize_kwargs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmlines\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLine2D\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1647\u001b[0;31m         \u001b[0mlines\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_lines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1648\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlines\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1649\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_line\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    214\u001b[0m                 \u001b[0mthis\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m                 \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m             \u001b[0;32myield\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_plot_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mthis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_next_color\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36m_plot_args\u001b[0;34m(self, tup, kwargs)\u001b[0m\n\u001b[1;32m    340\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    341\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 342\u001b[0;31m             raise ValueError(f\"x and y must have same first dimension, but \"\n\u001b[0m\u001b[1;32m    343\u001b[0m                              f\"have shapes {x.shape} and {y.shape}\")\n\u001b[1;32m    344\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: x and y must have same first dimension, but have shapes (10,) and (9,)"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1440x720 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}