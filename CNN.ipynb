{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CNNworking.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyP+p3Ou5WU/RHg1cJZw4vRn",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rfarwell/MPhys/blob/main/CNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fZBf3jpZGGbh",
        "outputId": "16e21eea-8c13-4344-c9e3-1e53f3d2d798"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (1.10.0+cu111)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.7/dist-packages (0.11.1+cu111)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch) (3.10.0.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchvision) (1.19.5)\n",
            "Requirement already satisfied: pillow!=8.3.0,>=5.3.0 in /usr/local/lib/python3.7/dist-packages (from torchvision) (7.1.2)\n",
            "Requirement already satisfied: opencv-contrib-python in /usr/local/lib/python3.7/dist-packages (4.1.2.30)\n",
            "Requirement already satisfied: numpy>=1.14.5 in /usr/local/lib/python3.7/dist-packages (from opencv-contrib-python) (1.19.5)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (1.0.1)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn) (1.4.1)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn) (3.0.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn) (1.1.0)\n",
            "Requirement already satisfied: numpy>=1.14.6 in /usr/local/lib/python3.7/dist-packages (from scikit-learn) (1.19.5)\n",
            "Collecting SimpleITK\n",
            "  Downloading SimpleITK-2.1.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (48.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 48.4 MB 25 kB/s \n",
            "\u001b[?25hInstalling collected packages: SimpleITK\n",
            "Successfully installed SimpleITK-2.1.1\n"
          ]
        }
      ],
      "source": [
        "!pip install torch torchvision\n",
        "!pip install opencv-contrib-python\n",
        "!pip install scikit-learn\n",
        "!pip install SimpleITK\n",
        "\n",
        "import numpy as np\n",
        "import random\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import SimpleITK as sitk\n",
        "import torch\n",
        "\n",
        "from mpl_toolkits.mplot3d import Axes3D\n",
        "from torch.nn import Module\n",
        "from torch.nn import Conv3d\n",
        "from torch.nn import Linear\n",
        "from torch.nn import MaxPool2d\n",
        "from torch.nn import ReLU\n",
        "from torch.nn import LogSoftmax\n",
        "from torch import flatten\n",
        "from torch import nn\n",
        "from torch import reshape\n",
        "from torch.utils.data import Dataset\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import transforms\n",
        "from torchvision import datasets\n",
        "from torch.optim import Adam\n",
        "import torchvision.models as models\n",
        "from torch.autograd import Variable"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G2ze8ubaGj3Q",
        "outputId": "28bd5265-9986-40b9-97a5-97d059ae226b"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Connect to GPU is available\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "print(f'Using {device} device')\n",
        "# /content/gdrive/MyDrive/MPhys/Data/COLAB-Clinical-Data.csv\n",
        "# Specify project folder location\n",
        "project_folder = \"/content/gdrive/MyDrive/Data\"\n",
        "clinical_data_filename = \"NSCLC-Radiomics-Clinical-Data.csv\"\n",
        "print(os.path.join(project_folder, clinical_data_filename))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RC58ZlEgGn-Q",
        "outputId": "c1fa2c52-c952-496c-bf92-d20883bc122e"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using cuda device\n",
            "/content/gdrive/MyDrive/Data/NSCLC-Radiomics-Clinical-Data.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def equalise_array_lengths(array_1, array_2) :\n",
        "  \"\"\"\n",
        "  This functions takes in the arguments of two lists and makes sure they are returned as the same length.\n",
        "\n",
        "  Rory Farwell 02/12/2021\n",
        "  \"\"\"\n",
        "  # output_array = []\n",
        "  if len(array_1) > len(array_2) :\n",
        "    array_1 = array_1[:len(array_2)]\n",
        "  elif len(array_1) < len(array_2) :\n",
        "    array_2 = array_2[:len(array_1)]\n",
        "  #print(np.vstack((array_1, array_2)))\n",
        "  # output_array.append(array_1)\n",
        "  # output_array.append(array_2)\n",
        "  return (array_1, array_2)\n",
        "\n",
        "def remove_same_elements(small_array, long_array) :\n",
        "  \"\"\"\n",
        "  For use in the context, all the elements in small_array come from long_array.\n",
        "  This function will remove all of the elements used in small_array from_long_array.  \n",
        "  \"\"\"\n",
        "  for element in small_array :\n",
        "    long_array.remove(element)\n",
        "  return long_array\n",
        "\n",
        "def create_subgroup(input_array, original_array_length, desired_percentage) :\n",
        "  \"\"\"\n",
        "  This function outputs a subgroup array (e.g. training array) using a specified output array name,\n",
        "  input array and percentage length\n",
        "  \"\"\"\n",
        "  desired_length = int(original_array_length * desired_percentage)\n",
        "  output_array = random.sample(input_array, desired_length)\n",
        "  return output_array\n",
        "  \n",
        "\n",
        "# Open the metadata.csv file, convert to an array, and remove column headers\n",
        "metadata_file = os.path.join(project_folder, clinical_data_filename)\n",
        "metadata = np.genfromtxt(metadata_file, comments = '%', dtype=\"str\", delimiter=\",\")\n",
        "print(f\"Length of metadata array is {len(metadata)}\")\n",
        "\n",
        "outcome_type = 1 #int(input(\"Select which outcome you are aiming to predict \\n(1=Locoregional, 2=Distant Metastasis, 3=Death):\"))\n",
        "check_day = 3000 #int(input(\"Select the number of days at which to check for event:\"))\n",
        "which_patients = 1 #int(input(\"Do you want to include patients whose last follow up is before the check day? (no = 0, yes = 1):\"))\n",
        "patient_with_event = []\n",
        "patient_no_event = []\n",
        "outcomes_train = []\n",
        "outcomes_test = []\n",
        "images = []\n",
        "\n",
        "check_day = 365 * 1.5 # This is defining the timeframe for which our CNN will consider the binary output (in days)\n",
        "\n",
        "patient_IDs = metadata[:,0]\n",
        "time_markers = metadata[:,8]\n",
        "dead_statuses = metadata[:,9]\n",
        "\n",
        "time_markers = time_markers.astype(np.float32)\n",
        "dead_statuses = dead_statuses.astype(np.float32)\n",
        "\n",
        "\n",
        "check_day_dead_statuses = []\n",
        "\n",
        "counter = 0 \n",
        "\n",
        "dead_counter = 0\n",
        "alive_counter = 0\n",
        "no_info_counter = 0\n",
        "\n",
        "dead_patient_array = []\n",
        "alive_patient_array = []\n",
        "\n",
        "for i in range(len(dead_statuses)) :\n",
        "  # counter+=1\n",
        "  # print(counter)\n",
        "  temp_dead_status = dead_statuses[i]\n",
        "  #print(temp_dead_status)\n",
        "  temp_time_marker = time_markers[i]\n",
        "  #print(temp_time_marker)\n",
        "  if temp_dead_status == 1 : #if the patient is dead\n",
        "    #print('y')\n",
        "    if temp_time_marker < check_day :\n",
        "      check_day_dead_statuses.append(1) #confirms that the patient was dead after time 'check_day'\n",
        "      dead_patient_array.append([patient_IDs[i], 1])\n",
        "      dead_counter += 1\n",
        "      continue\n",
        "    elif temp_time_marker > check_day :\n",
        "      check_day_dead_statuses.append(0)\n",
        "      alive_patient_array.append([patient_IDs[i], 0])\n",
        "      alive_counter += 1\n",
        "      continue\n",
        "  elif temp_dead_status == 0 : #if the patient is alive\n",
        "    #print('n')\n",
        "    if temp_time_marker < check_day :\n",
        "      no_info_counter += 1\n",
        "      continue\n",
        "    elif temp_time_marker > check_day :\n",
        "      check_day_dead_statuses.append(0)\n",
        "      alive_patient_array.append([patient_IDs[i], 0])\n",
        "      alive_counter += 1\n",
        "      continue\n",
        "print(f\"Dead counter after {check_day} days: {dead_counter}\")\n",
        "print(f\"Alive counter after {check_day} days: {alive_counter}\")\n",
        "print(f\"No-info counter after {check_day} days: {no_info_counter}\")\n",
        "\n",
        "# print(len(dead_patient_array), dead_patient_array)\n",
        "# print(len(alive_patient_array), alive_patient_array)\n",
        "\n",
        "training_array = []\n",
        "testing_array = []\n",
        "validation_array = []\n",
        "\n",
        "random.shuffle(dead_patient_array) #shuffling both arrays to ensure random selection of patient data\n",
        "random.shuffle(alive_patient_array)\n",
        "\n",
        "# equalising the length of the 'dead' and 'alive' arrays so that we can ensure optimum training proportions\n",
        "new_dead_patient_array = equalise_array_lengths(dead_patient_array, alive_patient_array)[0]\n",
        "new_alive_patient_array = equalise_array_lengths(dead_patient_array, alive_patient_array)[1]\n",
        "print(f\"The alive and dead arrays have been sorted (randomly) so that they are both of length {len(new_dead_patient_array)}\")\n",
        "\n",
        "# print(new_dead_patient_array)\n",
        "# print(new_alive_patient_array)\n",
        "# print(len(new_dead_patient_array))\n",
        "# print(len(new_alive_patient_array))\n",
        "\n",
        "equalised_array_length = len(new_alive_patient_array)\n",
        "\n",
        "train_patients_dead = create_subgroup(new_dead_patient_array, equalised_array_length, 0.7)\n",
        "train_patients_alive = create_subgroup(new_alive_patient_array, equalised_array_length, 0.7)\n",
        "# print(len(train_patients_dead))\n",
        "# print(len(train_patients_alive))\n",
        "\n",
        "new_dead_patient_array = remove_same_elements(train_patients_dead, new_dead_patient_array)\n",
        "new_alive_patient_array = remove_same_elements(train_patients_alive, new_alive_patient_array)\n",
        "# print(len(new_dead_patient_array))\n",
        "# print(len(new_alive_patient_array))\n",
        "\n",
        "test_patients_dead = create_subgroup(new_dead_patient_array, equalised_array_length, 0.15)\n",
        "test_patients_alive = create_subgroup(new_alive_patient_array, equalised_array_length, 0.15)\n",
        "# print(len(test_patients_dead))\n",
        "# print(len(test_patients_alive))\n",
        "\n",
        "new_dead_patient_array = remove_same_elements(test_patients_dead, new_dead_patient_array)\n",
        "new_alive_patient_array = remove_same_elements(test_patients_alive, new_alive_patient_array)\n",
        "# print(len(new_dead_patient_array))\n",
        "# print(len(new_alive_patient_array))\n",
        "\n",
        "validate_patients_dead = create_subgroup(new_dead_patient_array, equalised_array_length, 0.15)\n",
        "validate_patients_alive = create_subgroup(new_alive_patient_array, equalised_array_length, 0.15)\n",
        "# print(len(validate_patients_dead))\n",
        "# print(len(validate_patients_alive))\n",
        "\n",
        "new_dead_patient_array = remove_same_elements(validate_patients_dead, new_dead_patient_array)\n",
        "new_alive_patient_array = remove_same_elements(validate_patients_alive, new_alive_patient_array)\n",
        "# print(len(new_dead_patient_array))\n",
        "# print(len(new_alive_patient_array))\n",
        "\n",
        "\n",
        "outcomes_train = train_patients_dead + train_patients_alive\n",
        "outcomes_test = test_patients_dead + test_patients_alive\n",
        "outcomes_validate = validate_patients_dead + validate_patients_alive\n",
        "\n",
        "print(len(outcomes_train))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0v-sZ9qRG2k2",
        "outputId": "355d1f31-4f38-4b44-fb53-8b7c19358caf"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Length of metadata array is 400\n",
            "Dead counter after 547.5 days: 200\n",
            "Alive counter after 547.5 days: 200\n",
            "No-info counter after 547.5 days: 0\n",
            "The alive and dead arrays have been sorted (randomly) so that they are both of length 200\n",
            "280\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from torchvision.io import read_image\n",
        "\n",
        "# Normalize class added at 10pm 12/12/2021\n",
        "class Normalize():\n",
        "  def __init__(self):\n",
        "    pass\n",
        "  \n",
        "  # def __call__(self, sample):\n",
        "  #   inputs, targets = sample\n",
        "  #   inputs = transforms.Normalize(mean = 0.5, std = 0.5)\n",
        "  #   return inputs, targets\n",
        "  def __call__(self,vol):\n",
        "    vol =(vol-vol.mean())/vol.std()\n",
        "    return vol\n",
        "\n",
        "transform = transforms.Compose(\n",
        "    [transforms.ToTensor(), transforms.Normalize(mean = 0.5, std = 0.5)] #added at 10:31pm 13/12/2021 to normalize the inputs\n",
        ")\n",
        "\n",
        "transform = transforms.Compose(\n",
        "    [transforms.ToTensor(), Normalize() ] #added at 11:00pm 13/12/2021 to normalize the inputs. THIS NORMALIZES to mean = 0 and std = -1\n",
        ")\n",
        "\n",
        "\n",
        "class ImageDataset(Dataset) :\n",
        "  def __init__(self, annotations, img_dir, transform = transform, target_transform = None) :\n",
        "    self.img_labels = annotations\n",
        "    self.img_dir = img_dir\n",
        "    self.transform = transform\n",
        "    self.target_transform = target_transform\n",
        "\n",
        "  def __len__(self) :\n",
        "    return len(self.img_labels)\n",
        "\n",
        "  def __getitem__(self,idx) :\n",
        "    img_path = os.path.join(self.img_dir, self.img_labels[idx][0] + \"-GTV-1.nii\" )\n",
        "    image_sitk = sitk.ReadImage(img_path)\n",
        "    image = sitk.GetArrayFromImage(image_sitk)\n",
        "    label = self.img_labels[idx][1]\n",
        "    if self.transform :\n",
        "      image = self.transform(image)\n",
        "    if self.target_transform :\n",
        "      label = self.target_transform(label)\n",
        "    return image,label\n",
        "\n",
        "training_data = ImageDataset(outcomes_train, os.path.join(project_folder, \"Textured_Masks\"), transform = transforms.ToTensor())\n",
        "validation_data = ImageDataset(outcomes_validate, os.path.join(project_folder, \"Textured_Masks\"), transform = transforms.ToTensor())\n",
        "test_data = ImageDataset(outcomes_test, os.path.join(project_folder, \"Textured_Masks\"), transform = transforms.ToTensor())\n",
        "print(training_data[0][0][0][0][0])\n",
        "print(training_data[0][0].mean(), training_data[0][0].std())\n",
        "print(training_data[0][1])\n",
        "print(training_data[1][0][0][0][0])\n",
        "print(training_data[1][0].mean(), training_data[1][0].std())\n",
        "print(training_data[1][1])\n",
        "\n",
        "training_data = ImageDataset(outcomes_train, os.path.join(project_folder, \"Textured_Masks\"), transform = transform)\n",
        "validation_data = ImageDataset(outcomes_validate, os.path.join(project_folder, \"Textured_Masks\"), transform = transform)\n",
        "test_data = ImageDataset(outcomes_test, os.path.join(project_folder, \"Textured_Masks\"), transform = transform) \n",
        "print(training_data[0][0][0][0][0])\n",
        "print(training_data[0][0].mean(), training_data[0][0].std())\n",
        "print(training_data[0][1])\n",
        "print(training_data[1][0][0][0][0])\n",
        "print(training_data[1][0].mean(), training_data[1][0].std())\n",
        "print(training_data[1][1])\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mXcJcHb-G9yw",
        "outputId": "cc91d96d-79bc-4f7c-89a8-ef4633570e3a"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(-1024.)\n",
            "tensor(-1023.1797) tensor(28.1385)\n",
            "1\n",
            "tensor(-1024.)\n",
            "tensor(-1021.3135) tensor(52.9411)\n",
            "1\n",
            "tensor(-0.0292)\n",
            "tensor(-7.4793e-07) tensor(1.)\n",
            "1\n",
            "tensor(-0.0507)\n",
            "tensor(-4.3455e-07) tensor(1.0000)\n",
            "1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataloader = DataLoader(training_data, batch_size = 4, shuffle = True)\n",
        "test_dataloader = DataLoader(test_data, batch_size = 4, shuffle = False)\n",
        "validation_dataloader = DataLoader(validation_data, batch_size = 4, shuffle = True)\n"
      ],
      "metadata": {
        "id": "FTrTQJAJHFPW"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class CNN(nn.Module):   \n",
        "    def __init__(self):\n",
        "        super(CNN, self).__init__()\n",
        "        self.conv1 = nn.Conv3d(1,4,2,2)\n",
        "        self.pool = nn.MaxPool3d(2,2)\n",
        "        self.conv2 = nn.Conv3d(4,16,22)\n",
        "        self.conv3 = nn.Conv3d(16,64,2,2)\n",
        "        self.conv4 = nn.Conv3d(64,256,2,2)\n",
        "        self.fc1 = nn.Linear(256,64)\n",
        "        self.fc2 = nn.Linear(64,16)\n",
        "        self.fc3 = nn.Linear(16,2)\n",
        "\n",
        "    # Defining the forward pass    \n",
        "    def forward(self, x):\n",
        "        x = self.pool(F.leaky_relu(self.conv1(x)))\n",
        "        x = self.pool(F.leaky_relu(self.conv2(x)))\n",
        "        x = self.pool(F.leaky_relu(self.conv3(x)))\n",
        "        x = self.pool(F.leaky_relu(self.conv4(x)))\n",
        "        x = x.view(-1, 256)\n",
        "        x = F.leaky_relu(self.fc1(x))\n",
        "        x = F.leaky_relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        # return F.leaky_relu(x)\n",
        "        return x\n",
        "  \n",
        "model = CNN().to(device)"
      ],
      "metadata": {
        "id": "srBmMr4qHJKE"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torchsummary import summary\n",
        "summary(model, (1,264,264,264), batch_size = 4)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XL_AkLSvHL_s",
        "outputId": "3c7ed350-6e40-43fa-a740-85f5486289d8"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv3d-1      [4, 4, 132, 132, 132]              36\n",
            "         MaxPool3d-2         [4, 4, 66, 66, 66]               0\n",
            "            Conv3d-3        [4, 16, 45, 45, 45]         681,488\n",
            "         MaxPool3d-4        [4, 16, 22, 22, 22]               0\n",
            "            Conv3d-5        [4, 64, 11, 11, 11]           8,256\n",
            "         MaxPool3d-6           [4, 64, 5, 5, 5]               0\n",
            "            Conv3d-7          [4, 256, 2, 2, 2]         131,328\n",
            "         MaxPool3d-8          [4, 256, 1, 1, 1]               0\n",
            "            Linear-9                    [4, 64]          16,448\n",
            "           Linear-10                    [4, 16]           1,040\n",
            "           Linear-11                     [4, 2]              34\n",
            "================================================================\n",
            "Total params: 838,630\n",
            "Trainable params: 838,630\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 280.76\n",
            "Forward/backward pass size (MB): 368.46\n",
            "Params size (MB): 3.20\n",
            "Estimated Total Size (MB): 652.42\n",
            "----------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# loss and optimizer\n",
        "learning_rate = 0.001\n",
        "criterion = nn.BCEWithLogitsLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr = learning_rate)"
      ],
      "metadata": {
        "id": "O7yVCxOzHOkz"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#training_loop\n",
        "num_epochs = 20\n",
        "n_total_steps = len(train_dataloader)\n",
        "print(n_total_steps)\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "  print(f'Training for epoch {epoch+1}')\n",
        "  print('=============================================')\n",
        "  for i, (images, labels) in enumerate(train_dataloader):\n",
        "    images = reshape(images, (images.shape[0],1 ,264,264,264))\n",
        "    images = images.float()\n",
        "    #print(labels)\n",
        "    hot_labels = torch.empty((images.shape[0], 2))\n",
        "    #print(new_labels.shape)\n",
        "    for index in range(len(labels)):\n",
        "          if labels[index] == 0 :\n",
        "            hot_labels[index,0] = 1\n",
        "            hot_labels[index,1] = 0\n",
        "          elif labels[index] == 1 :\n",
        "            hot_labels[index,0] = 0\n",
        "            hot_labels[index,1] = 1\n",
        "    images = images.to(device)\n",
        "    hot_labels = hot_labels.to(device)\n",
        "\n",
        "    # avoiding time out\n",
        "\n",
        "    #forward pass\n",
        "    outputs = model(images)\n",
        "    #print(outputs)\n",
        "    loss = criterion(outputs, hot_labels)\n",
        "\n",
        "    #backwards pass\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if (i+1)%10 == 0:\n",
        "      print(f'Epoch {epoch+1}/{num_epochs}, step {i+1}/{n_total_steps}, loss = {loss.item():.4f}')\n",
        "  print(f'Finished training for epoch {epoch+1}')\n",
        "  print(f'Validation for epoch {epoch+1}')\n",
        "  print('=============================================')\n",
        "  with torch.no_grad():\n",
        "    n_correct = 0\n",
        "    n_samples = 0\n",
        "    for images, labels in validation_dataloader :\n",
        "      images = images = reshape(images, (images.shape[0],1 ,264,264,264))\n",
        "      images = images.float()\n",
        "      hot_labels = torch.empty((images.shape[0], 2))\n",
        "      #print(new_labels.shape)\n",
        "      for index in range(len(labels)):\n",
        "          if labels[index] == 0 :\n",
        "            hot_labels[index,0] = 1\n",
        "            hot_labels[index,1] = 0\n",
        "          elif labels[index] == 1 :\n",
        "            hot_labels[index,0] = 0\n",
        "            hot_labels[index,1] = 1\n",
        "      images = images.to(device)\n",
        "      hot_labels = hot_labels.to(device)\n",
        "      outputs = model(images)\n",
        "      # max returns (value, index) \n",
        "      _,predictions = torch.max(outputs, 1)\n",
        "      _,targets = torch.max(hot_labels, 1)\n",
        "      print(f'predictions: {predictions}')\n",
        "      print(f'targets: {targets}')\n",
        "      print(f'correct in this batch: {(predictions == targets).sum().item()}')\n",
        "      n_samples += labels.shape[0]\n",
        "      n_correct += (predictions == targets).sum().item()\n",
        "      print(f'n_correct = {n_correct}. n_samples = {n_samples}')\n",
        "\n",
        "    acc = (100*n_correct)/n_samples\n",
        "    print(f'Accuracy on validation set for epoch {epoch+1} = {acc:.1f}%')\n",
        "\n",
        "    print(f'Finished validation for epoch {epoch+1}')\n",
        "    print('=============================================')\n",
        "\n",
        "print('FINISHED TRAINING')\n",
        "\n",
        "#testing\n",
        "with torch.no_grad():\n",
        "    n_correct = 0\n",
        "    n_samples = 0\n",
        "    for images, labels in test_dataloader :\n",
        "      images = images = reshape(images, (images.shape[0],1 ,264,264,264))\n",
        "      images = images.float()\n",
        "      hot_labels = torch.empty((images.shape[0], 2))\n",
        "      #print(new_labels.shape)\n",
        "      for index in range(len(labels)):\n",
        "          if labels[index] == 0 :\n",
        "            hot_labels[index,0] = 1\n",
        "            hot_labels[index,1] = 0\n",
        "          elif labels[index] == 1 :\n",
        "            hot_labels[index,0] = 0\n",
        "            hot_labels[index,1] = 1\n",
        "      images = images.to(device)\n",
        "      hot_labels = hot_labels.to(device)\n",
        "      outputs = model(images)\n",
        "      # max returns (value, index) \n",
        "      _,predictions = torch.max(outputs, 1)\n",
        "      _,targets = torch.max(hot_labels,1)\n",
        "      print(f'predictions: {predictions}')\n",
        "      print(f'targets: {targets}')\n",
        "      n_samples += hot_labels.shape[0]\n",
        "      n_correct += (predictions == targets).sum().item()\n",
        "      print(f'n_correct = {n_correct}. n_samples = {n_samples}')\n",
        "    \n",
        "    acc = (100*n_correct)/n_samples\n",
        "    print(f'Accuracy on training set = {acc:.1f}%')\n",
        "\n",
        "# another time renewal\n",
        "# and again\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "N_zXLDFOHXD-",
        "outputId": "13eeae6f-3f82-4e9b-f0a5-ab4896fbcc39"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "70\n",
            "Training for epoch 1\n",
            "=============================================\n",
            "Epoch 1/20, step 10/70, loss = 0.7300\n",
            "Epoch 1/20, step 20/70, loss = 0.6974\n",
            "Epoch 1/20, step 30/70, loss = 0.6572\n",
            "Epoch 1/20, step 40/70, loss = 0.6915\n",
            "Epoch 1/20, step 50/70, loss = 0.6835\n",
            "Epoch 1/20, step 60/70, loss = 0.7284\n",
            "Epoch 1/20, step 70/70, loss = 0.7337\n",
            "Finished training for epoch 1\n",
            "Validation for epoch 1\n",
            "=============================================\n",
            "predictions: tensor([0, 0, 0, 0], device='cuda:0')\n",
            "targets: tensor([1, 1, 0, 1], device='cuda:0')\n",
            "correct in this batch: 1\n",
            "n_correct = 1. n_samples = 4\n",
            "predictions: tensor([0, 0, 0, 0], device='cuda:0')\n",
            "targets: tensor([1, 1, 1, 1], device='cuda:0')\n",
            "correct in this batch: 0\n",
            "n_correct = 1. n_samples = 8\n",
            "predictions: tensor([0, 0, 0, 0], device='cuda:0')\n",
            "targets: tensor([1, 0, 0, 0], device='cuda:0')\n",
            "correct in this batch: 3\n",
            "n_correct = 4. n_samples = 12\n",
            "predictions: tensor([0, 0, 0, 0], device='cuda:0')\n",
            "targets: tensor([1, 0, 0, 1], device='cuda:0')\n",
            "correct in this batch: 2\n",
            "n_correct = 6. n_samples = 16\n",
            "predictions: tensor([0, 0, 0, 0], device='cuda:0')\n",
            "targets: tensor([0, 0, 1, 0], device='cuda:0')\n",
            "correct in this batch: 3\n",
            "n_correct = 9. n_samples = 20\n",
            "predictions: tensor([0, 0, 0, 0], device='cuda:0')\n",
            "targets: tensor([0, 0, 0, 1], device='cuda:0')\n",
            "correct in this batch: 3\n",
            "n_correct = 12. n_samples = 24\n",
            "predictions: tensor([0, 0, 0, 0], device='cuda:0')\n",
            "targets: tensor([1, 0, 1, 1], device='cuda:0')\n",
            "correct in this batch: 1\n",
            "n_correct = 13. n_samples = 28\n",
            "predictions: tensor([0, 0, 0, 0], device='cuda:0')\n",
            "targets: tensor([1, 0, 0, 0], device='cuda:0')\n",
            "correct in this batch: 3\n",
            "n_correct = 16. n_samples = 32\n",
            "predictions: tensor([0, 0, 0, 0], device='cuda:0')\n",
            "targets: tensor([0, 0, 1, 1], device='cuda:0')\n",
            "correct in this batch: 2\n",
            "n_correct = 18. n_samples = 36\n",
            "predictions: tensor([0, 0, 0, 0], device='cuda:0')\n",
            "targets: tensor([0, 0, 1, 1], device='cuda:0')\n",
            "correct in this batch: 2\n",
            "n_correct = 20. n_samples = 40\n",
            "predictions: tensor([0, 0, 0, 0], device='cuda:0')\n",
            "targets: tensor([1, 0, 1, 1], device='cuda:0')\n",
            "correct in this batch: 1\n",
            "n_correct = 21. n_samples = 44\n",
            "predictions: tensor([0, 0, 0, 0], device='cuda:0')\n",
            "targets: tensor([0, 1, 0, 1], device='cuda:0')\n",
            "correct in this batch: 2\n",
            "n_correct = 23. n_samples = 48\n",
            "predictions: tensor([0, 0, 0, 0], device='cuda:0')\n",
            "targets: tensor([0, 0, 1, 0], device='cuda:0')\n",
            "correct in this batch: 3\n",
            "n_correct = 26. n_samples = 52\n",
            "predictions: tensor([0, 0, 0, 0], device='cuda:0')\n",
            "targets: tensor([0, 1, 0, 0], device='cuda:0')\n",
            "correct in this batch: 3\n",
            "n_correct = 29. n_samples = 56\n",
            "predictions: tensor([0, 0, 0, 0], device='cuda:0')\n",
            "targets: tensor([0, 1, 1, 1], device='cuda:0')\n",
            "correct in this batch: 1\n",
            "n_correct = 30. n_samples = 60\n",
            "Accuracy on validation set for epoch 1 = 50.0%\n",
            "Finished validation for epoch 1\n",
            "=============================================\n",
            "Training for epoch 2\n",
            "=============================================\n",
            "Epoch 2/20, step 10/70, loss = 0.6848\n",
            "Epoch 2/20, step 20/70, loss = 0.6591\n",
            "Epoch 2/20, step 30/70, loss = 0.6522\n",
            "Epoch 2/20, step 40/70, loss = 0.6588\n",
            "Epoch 2/20, step 50/70, loss = 0.6865\n",
            "Epoch 2/20, step 60/70, loss = 0.6475\n",
            "Epoch 2/20, step 70/70, loss = 0.8706\n",
            "Finished training for epoch 2\n",
            "Validation for epoch 2\n",
            "=============================================\n",
            "predictions: tensor([0, 0, 1, 0], device='cuda:0')\n",
            "targets: tensor([0, 0, 0, 0], device='cuda:0')\n",
            "correct in this batch: 3\n",
            "n_correct = 3. n_samples = 4\n",
            "predictions: tensor([0, 1, 0, 0], device='cuda:0')\n",
            "targets: tensor([1, 1, 1, 0], device='cuda:0')\n",
            "correct in this batch: 2\n",
            "n_correct = 5. n_samples = 8\n",
            "predictions: tensor([1, 0, 0, 1], device='cuda:0')\n",
            "targets: tensor([1, 0, 1, 1], device='cuda:0')\n",
            "correct in this batch: 3\n",
            "n_correct = 8. n_samples = 12\n",
            "predictions: tensor([0, 0, 0, 0], device='cuda:0')\n",
            "targets: tensor([1, 0, 0, 0], device='cuda:0')\n",
            "correct in this batch: 3\n",
            "n_correct = 11. n_samples = 16\n",
            "predictions: tensor([1, 0, 1, 0], device='cuda:0')\n",
            "targets: tensor([1, 0, 1, 0], device='cuda:0')\n",
            "correct in this batch: 4\n",
            "n_correct = 15. n_samples = 20\n",
            "predictions: tensor([0, 0, 1, 1], device='cuda:0')\n",
            "targets: tensor([0, 0, 1, 1], device='cuda:0')\n",
            "correct in this batch: 4\n",
            "n_correct = 19. n_samples = 24\n",
            "predictions: tensor([0, 0, 0, 0], device='cuda:0')\n",
            "targets: tensor([0, 1, 0, 0], device='cuda:0')\n",
            "correct in this batch: 3\n",
            "n_correct = 22. n_samples = 28\n",
            "predictions: tensor([0, 1, 0, 0], device='cuda:0')\n",
            "targets: tensor([1, 0, 0, 1], device='cuda:0')\n",
            "correct in this batch: 1\n",
            "n_correct = 23. n_samples = 32\n",
            "predictions: tensor([0, 1, 1, 0], device='cuda:0')\n",
            "targets: tensor([1, 1, 1, 1], device='cuda:0')\n",
            "correct in this batch: 2\n",
            "n_correct = 25. n_samples = 36\n",
            "predictions: tensor([0, 0, 1, 0], device='cuda:0')\n",
            "targets: tensor([1, 0, 1, 1], device='cuda:0')\n",
            "correct in this batch: 2\n",
            "n_correct = 27. n_samples = 40\n",
            "predictions: tensor([0, 0, 0, 1], device='cuda:0')\n",
            "targets: tensor([0, 0, 1, 1], device='cuda:0')\n",
            "correct in this batch: 3\n",
            "n_correct = 30. n_samples = 44\n",
            "predictions: tensor([0, 1, 1, 1], device='cuda:0')\n",
            "targets: tensor([0, 1, 0, 0], device='cuda:0')\n",
            "correct in this batch: 2\n",
            "n_correct = 32. n_samples = 48\n",
            "predictions: tensor([0, 1, 0, 0], device='cuda:0')\n",
            "targets: tensor([0, 1, 0, 0], device='cuda:0')\n",
            "correct in this batch: 4\n",
            "n_correct = 36. n_samples = 52\n",
            "predictions: tensor([1, 1, 0, 1], device='cuda:0')\n",
            "targets: tensor([1, 1, 0, 1], device='cuda:0')\n",
            "correct in this batch: 4\n",
            "n_correct = 40. n_samples = 56\n",
            "predictions: tensor([1, 0, 0, 1], device='cuda:0')\n",
            "targets: tensor([0, 0, 1, 1], device='cuda:0')\n",
            "correct in this batch: 2\n",
            "n_correct = 42. n_samples = 60\n",
            "Accuracy on validation set for epoch 2 = 70.0%\n",
            "Finished validation for epoch 2\n",
            "=============================================\n",
            "Training for epoch 3\n",
            "=============================================\n",
            "Epoch 3/20, step 10/70, loss = 0.6942\n",
            "Epoch 3/20, step 20/70, loss = 0.6582\n",
            "Epoch 3/20, step 30/70, loss = 0.6411\n",
            "Epoch 3/20, step 40/70, loss = 0.7530\n",
            "Epoch 3/20, step 50/70, loss = 0.6594\n",
            "Epoch 3/20, step 60/70, loss = 0.7008\n",
            "Epoch 3/20, step 70/70, loss = 0.6199\n",
            "Finished training for epoch 3\n",
            "Validation for epoch 3\n",
            "=============================================\n",
            "predictions: tensor([1, 1, 1, 1], device='cuda:0')\n",
            "targets: tensor([1, 0, 0, 0], device='cuda:0')\n",
            "correct in this batch: 1\n",
            "n_correct = 1. n_samples = 4\n",
            "predictions: tensor([0, 0, 1, 1], device='cuda:0')\n",
            "targets: tensor([0, 0, 1, 1], device='cuda:0')\n",
            "correct in this batch: 4\n",
            "n_correct = 5. n_samples = 8\n",
            "predictions: tensor([1, 0, 0, 0], device='cuda:0')\n",
            "targets: tensor([1, 1, 0, 1], device='cuda:0')\n",
            "correct in this batch: 2\n",
            "n_correct = 7. n_samples = 12\n",
            "predictions: tensor([1, 1, 1, 1], device='cuda:0')\n",
            "targets: tensor([1, 1, 1, 1], device='cuda:0')\n",
            "correct in this batch: 4\n",
            "n_correct = 11. n_samples = 16\n",
            "predictions: tensor([1, 1, 0, 0], device='cuda:0')\n",
            "targets: tensor([1, 0, 0, 1], device='cuda:0')\n",
            "correct in this batch: 2\n",
            "n_correct = 13. n_samples = 20\n",
            "predictions: tensor([0, 1, 1, 1], device='cuda:0')\n",
            "targets: tensor([0, 1, 1, 0], device='cuda:0')\n",
            "correct in this batch: 3\n",
            "n_correct = 16. n_samples = 24\n",
            "predictions: tensor([0, 1, 0, 0], device='cuda:0')\n",
            "targets: tensor([0, 1, 0, 1], device='cuda:0')\n",
            "correct in this batch: 3\n",
            "n_correct = 19. n_samples = 28\n",
            "predictions: tensor([1, 0, 1, 1], device='cuda:0')\n",
            "targets: tensor([0, 1, 0, 0], device='cuda:0')\n",
            "correct in this batch: 0\n",
            "n_correct = 19. n_samples = 32\n",
            "predictions: tensor([1, 1, 1, 0], device='cuda:0')\n",
            "targets: tensor([1, 1, 0, 0], device='cuda:0')\n",
            "correct in this batch: 3\n",
            "n_correct = 22. n_samples = 36\n",
            "predictions: tensor([0, 0, 0, 1], device='cuda:0')\n",
            "targets: tensor([1, 0, 0, 0], device='cuda:0')\n",
            "correct in this batch: 2\n",
            "n_correct = 24. n_samples = 40\n",
            "predictions: tensor([1, 0, 1, 1], device='cuda:0')\n",
            "targets: tensor([0, 0, 1, 1], device='cuda:0')\n",
            "correct in this batch: 3\n",
            "n_correct = 27. n_samples = 44\n",
            "predictions: tensor([1, 0, 0, 1], device='cuda:0')\n",
            "targets: tensor([1, 1, 1, 0], device='cuda:0')\n",
            "correct in this batch: 1\n",
            "n_correct = 28. n_samples = 48\n",
            "predictions: tensor([1, 0, 0, 0], device='cuda:0')\n",
            "targets: tensor([0, 0, 0, 0], device='cuda:0')\n",
            "correct in this batch: 3\n",
            "n_correct = 31. n_samples = 52\n",
            "predictions: tensor([1, 1, 1, 1], device='cuda:0')\n",
            "targets: tensor([0, 1, 1, 1], device='cuda:0')\n",
            "correct in this batch: 3\n",
            "n_correct = 34. n_samples = 56\n",
            "predictions: tensor([0, 1, 1, 1], device='cuda:0')\n",
            "targets: tensor([0, 0, 1, 1], device='cuda:0')\n",
            "correct in this batch: 3\n",
            "n_correct = 37. n_samples = 60\n",
            "Accuracy on validation set for epoch 3 = 61.7%\n",
            "Finished validation for epoch 3\n",
            "=============================================\n",
            "Training for epoch 4\n",
            "=============================================\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-c47606352b66>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     20\u001b[0m             \u001b[0mhot_labels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m             \u001b[0mhot_labels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m     \u001b[0mimages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m     \u001b[0mhot_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhot_labels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ]
}